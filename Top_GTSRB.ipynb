{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Top_GTSRB.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"}},"cells":[{"cell_type":"markdown","metadata":{"id":"YYXJwJMwiyun"},"source":["# Assignment 3 Part 1: Developing Your Own Classifier"]},{"cell_type":"code","metadata":{"id":"Q6YDS3Thleh5","executionInfo":{"status":"ok","timestamp":1605685593075,"user_tz":480,"elapsed":46608,"user":{"displayName":"Mohammad Karimi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhscZnXMfUg_B5TiqiYQWTpwdoSQgf3KMBVqAvcdx0=s64","userId":"12774174295451066351"}},"outputId":"e57fb802-fdea-4772-f3df-ddb1c3fb8ba6","colab":{"base_uri":"https://localhost:8080/"}},"source":["import os\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=False)\n","os.chdir(\"/content/drive/My Drive/A-Courses-PhD/Term_17_Fall2020/CS498-DL/assignments/Project/Explainable_GTSRB\")\n","#os.chdir(\"/content/drive/My Drive/CS498-DL/assignments/Assignment_03/My_assignment3_p1_starterkit\")\n"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"flUDGBpmJbmG","executionInfo":{"status":"ok","timestamp":1605685741790,"user_tz":480,"elapsed":148138,"user":{"displayName":"Mohammad Karimi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhscZnXMfUg_B5TiqiYQWTpwdoSQgf3KMBVqAvcdx0=s64","userId":"12774174295451066351"}},"outputId":"f053fed7-3232-4272-b247-7cfa7e3e205f","colab":{"base_uri":"https://localhost:8080/"}},"source":["!pip install torch==1.4.0 torchvision==0.5.0\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting torch==1.4.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/24/19/4804aea17cd136f1705a5e98a00618cb8f6ccc375ad8bfa437408e09d058/torch-1.4.0-cp36-cp36m-manylinux1_x86_64.whl (753.4MB)\n","\u001b[K     |████████████████████████████████| 753.4MB 21kB/s \n","\u001b[?25hCollecting torchvision==0.5.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/90/6141bf41f5655c78e24f40f710fdd4f8a8aff6c8b7c6f0328240f649bdbe/torchvision-0.5.0-cp36-cp36m-manylinux1_x86_64.whl (4.0MB)\n","\u001b[K     |████████████████████████████████| 4.0MB 38.5MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==0.5.0) (1.18.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision==0.5.0) (1.15.0)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.5.0) (7.0.0)\n","Installing collected packages: torch, torchvision\n","  Found existing installation: torch 1.7.0+cu101\n","    Uninstalling torch-1.7.0+cu101:\n","      Successfully uninstalled torch-1.7.0+cu101\n","  Found existing installation: torchvision 0.8.1+cu101\n","    Uninstalling torchvision-0.8.1+cu101:\n","      Successfully uninstalled torchvision-0.8.1+cu101\n","Successfully installed torch-1.4.0 torchvision-0.5.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GaOqSjzxiyup","executionInfo":{"status":"ok","timestamp":1605685744234,"user_tz":480,"elapsed":2402,"user":{"displayName":"Mohammad Karimi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhscZnXMfUg_B5TiqiYQWTpwdoSQgf3KMBVqAvcdx0=s64","userId":"12774174295451066351"}}},"source":["import os\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torchvision\n","\n","import PIL\n","from torchvision import transforms\n","from sklearn.metrics import average_precision_score\n","from PIL import Image, ImageDraw\n","import matplotlib.pyplot as plt\n","#from kaggle_submission import output_submission_csv\n","from classifier import SimpleClassifier, Classifier, Classifier_moreConv#, AlexNet\n","#from voc_dataloader import VocDataset, VOC_CLASSES\n","from dataloader import MyDataset, My_classes\n","import pickle\n","\n","from sklearn.model_selection import train_test_split\n","\n","%matplotlib inline\n","%load_ext autoreload\n","%autoreload 2\n","\n","path ='/content/GTSRB_data/'\n","#path = 'G:/My Drive/A-Courses-PhD/Term_17_Fall2020/CS498-DL/assignments/Project/gtsrb-german-traffic-sign/GTSRB_data'\n","num_classes = len(My_classes)\n","result_path = ''"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"b6g5m8ZxKESG","executionInfo":{"status":"ok","timestamp":1605685763122,"user_tz":480,"elapsed":21281,"user":{"displayName":"Mohammad Karimi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhscZnXMfUg_B5TiqiYQWTpwdoSQgf3KMBVqAvcdx0=s64","userId":"12774174295451066351"}}},"source":["if 0:\n","  import shutil \n","  shutil.copyfile(\"GTSRB_data.tar\", \"/content/GTSRB_data.tar\")\n","  !tar -xf \"/content/GTSRB_data.tar\" -C \"/content/\" \n","  #shutil.move(\"/content/VOCdevkit/\", \"/content/VOCdevkit_2007\")\n"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"S4Chtrwviyus"},"source":["# Part 1B: Design your own network\n","\n","In this notebook, your task is to create and train your own model for multi-label classification on VOC Pascal.\n","\n","## What to do\n","1. You will make change on network architecture in ```classifier.py```.\n","2. You may also want to change other hyperparameters to assist your training to get a better performances. Hints will be given in the below instructions.\n","\n","## What to submit\n","Check the submission template for details what to submit. "]},{"cell_type":"code","metadata":{"id":"nd7MIVBQiyut"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bCcQkmp4iyuv","executionInfo":{"status":"ok","timestamp":1605685764256,"user_tz":480,"elapsed":397,"user":{"displayName":"Mohammad Karimi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhscZnXMfUg_B5TiqiYQWTpwdoSQgf3KMBVqAvcdx0=s64","userId":"12774174295451066351"}}},"source":["def train_classifier(train_loader, classifier, criterion, optimizer):\n","    classifier.train()\n","    loss_ = 0.0\n","    losses = []\n","    for i, (images, labels, _) in enumerate(train_loader):\n","        images, labels = images.to(device), labels.to(device)\n","        optimizer.zero_grad()\n","        logits = classifier(images)\n","        loss = criterion(logits, labels)\n","        loss.backward()\n","        optimizer.step()\n","        losses.append(loss)\n","    return torch.stack(losses).mean().item()\n","\n","def test_classifier(test_loader, classifier, criterion, print_ind_classes=True, print_total=True):\n","    classifier.eval()\n","    losses = []\n","    with torch.no_grad():\n","        y_true = np.zeros((0,num_classes))\n","        y_score = np.zeros((0,num_classes))\n","        for i, (images, labels, _) in enumerate(test_loader):\n","            images, labels = images.to(device), labels.to(device)\n","            logits = classifier(images)\n","            y_true = np.concatenate((y_true, labels.cpu().numpy()), axis=0)\n","            y_score = np.concatenate((y_score, logits.cpu().numpy()), axis=0)\n","            loss = criterion(logits, labels)\n","            losses.append(loss.item())\n","        aps = []\n","        # ignore first class which is background\n","        for i in range(0, y_true.shape[1]):\n","            ap = average_precision_score(y_true[:, i], y_score[:, i])\n","            if print_ind_classes:\n","                print('-------  Class: {:<12}     AP: {:>8.4f}  -------'.format(My_classes[i], ap))\n","            aps.append(ap)\n","        \n","        mAP = np.mean(aps)\n","        test_loss = np.mean(losses)\n","        if print_total:\n","            print('mAP: {0:.4f}'.format(mAP))\n","            print('Avg loss: {}'.format(test_loss))\n","        \n","    return mAP, test_loss, aps\n","\n","def plot_losses(train, val, test_frequency, num_epochs):\n","    plt.plot(train, label=\"train\")\n","    indices = [i for i in range(num_epochs) if ((i+1)%test_frequency == 0 or i ==0)]\n","    plt.plot(indices, val, label=\"val\")\n","    plt.title(\"Loss Plot\")\n","    plt.ylabel(\"Loss\")\n","    plt.xlabel(\"Epoch\")\n","    plt.legend()\n","    plt.show()\n","    \n","def plot_mAP(train, val, test_frequency, num_epochs):\n","    indices = [i for i in range(num_epochs) if ((i+1)%test_frequency == 0 or i ==0)]\n","    plt.plot(indices, train, label=\"train\")\n","    plt.plot(indices, val, label=\"val\")\n","    plt.title(\"mAP Plot\")\n","    plt.ylabel(\"mAP\")\n","    plt.xlabel(\"Epoch\")\n","    plt.legend()\n","    plt.show()\n","    \n","\n","def train(classifier, num_epochs, train_loader, val_loader, criterion, optimizer, test_frequency=5):\n","    train_losses = []\n","    train_mAPs = []\n","    val_losses = []\n","    val_mAPs = []\n","    decayRate = 0.96\n","    \n","\n","    for epoch in range(1,num_epochs+1):\n","        print(\"Starting epoch number \" + str(epoch))\n","        train_loss = train_classifier(train_loader, classifier, criterion, optimizer)\n","        train_losses.append(train_loss)\n","        #lr_scheduler.step()\n","        #print('learning rate :', get_lr(lr_scheduler.optimizer))\n","\n","        print(\"Loss for Training on Epoch \" +str(epoch) + \" is \"+ str(train_loss))\n","        if(epoch%test_frequency==0 or epoch==1):\n","            mAP_train, _, _ = test_classifier(train_loader, classifier, criterion, False, False)\n","            train_mAPs.append(mAP_train)\n","            mAP_val, val_loss, _ = test_classifier(val_loader, classifier, criterion)\n","            print('Evaluating classifier')\n","            print(\"Mean Precision Score for Testing on Epoch \" +str(epoch) + \" is \"+ str(mAP_val))\n","            val_losses.append(val_loss)\n","            val_mAPs.append(mAP_val)\n","    \n","    return classifier, train_losses, val_losses, train_mAPs, val_mAPs\n","\n","    "],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4HDJRrpBiyu3"},"source":["# Developing Your Own Model"]},{"cell_type":"markdown","metadata":{"id":"eENCD04wiyu3"},"source":["### Goal\n","To meet the benchmark for this assignment you will need to improve the network. Note you should have noticed pretrained Alenxt performs really well, but training Alexnet from scratch performs much worse. We hope you can design a better architecture over both the simple classifier and AlexNet to train from scratch.\n","\n","### How to start\n","You may take inspiration from other published architectures and architectures discussed in lecture. However, you are NOT allowed to use predefined models (e.g. models from torchvision) or use pretrained weights. Training must be done from scratch with your own custom model.\n","\n","#### Some hints\n","There are a variety of different approaches you should try to improve performance from the simple classifier:\n","\n","* Network architecture changes\n","    * Number of layers: try adding layers to make your network deeper\n","    * Batch normalization: adding batch norm between layers will likely give you a significant performance increase\n","    * Residual connections: as you increase the depth of your network, you will find that having residual connections like those in ResNet architectures will be helpful\n","* Optimizer: Instead of plain SGD, you may want to add a learning rate schedule, add momentum, or use one of the other optimizers you have learned about like Adam. Check the `torch.optim` package for other optimizers\n","* Data augmentation: You should use the `torchvision.transforms` module to try adding random resized crops and horizontal flips of the input data. Check `transforms.RandomResizedCrop` and `transforms.RandomHorizontalFlip` for this. Feel free to apply more [transforms](https://pytorch.org/docs/stable/torchvision/transforms.html) for data augmentation which can lead to better performance. \n","* Epochs: Once you have found a generally good hyperparameter setting try training for more epochs\n","* Loss function: You might want to add weighting to the `MultiLabelSoftMarginLoss` for classes that are less well represented or experiment with a different loss function\n","\n","\n","\n","#### Note\n","We will soon be providing some initial expectations of mAP values as a function of epoch so you can get an early idea whether your implementation works without waiting a long time for training to converge.\n","\n","### What to submit \n","Submit your best model to Kaggle and save all plots for the writeup.\n"]},{"cell_type":"code","metadata":{"id":"6HwbEiH_2XTd","executionInfo":{"status":"ok","timestamp":1605685764460,"user_tz":480,"elapsed":592,"user":{"displayName":"Mohammad Karimi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhscZnXMfUg_B5TiqiYQWTpwdoSQgf3KMBVqAvcdx0=s64","userId":"12774174295451066351"}}},"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"4pyVJsYSiyu4","executionInfo":{"status":"ok","timestamp":1605685764460,"user_tz":480,"elapsed":587,"user":{"displayName":"Mohammad Karimi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhscZnXMfUg_B5TiqiYQWTpwdoSQgf3KMBVqAvcdx0=s64","userId":"12774174295451066351"}}},"source":["\n","\n","normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                                     std= [0.229, 0.224, 0.225])\n","\n","train_transform = transforms.Compose([\n","            #torchvision.transforms.ColorJitter(hue=.1, saturation=.05),\n","            #torchvision.transforms.RandomHorizontalFlip(),\n","            #torchvision.transforms.RandomRotation(10, resample=PIL.Image.BILINEAR),\n","            transforms.Resize(227),\n","            transforms.CenterCrop(227),\n","            transforms.ToTensor(),\n","            normalize\n","        ])\n","\n","test_transform = transforms.Compose([\n","            transforms.Resize(227),\n","            transforms.CenterCrop(227),\n","            transforms.ToTensor(),\n","            normalize,\n","        ])\n","\n"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"E_ZYj8PNJWs6","executionInfo":{"status":"ok","timestamp":1605685771686,"user_tz":480,"elapsed":7795,"user":{"displayName":"Mohammad Karimi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhscZnXMfUg_B5TiqiYQWTpwdoSQgf3KMBVqAvcdx0=s64","userId":"12774174295451066351"}},"outputId":"27aad1cb-cde1-4d81-f98d-e6b4550429fc","colab":{"base_uri":"https://localhost:8080/"}},"source":["#Randomize the order of the input images\n","#s=np.arange(ds_train.names.shape[0])\n","s=np.arange(39209)\n","#np.random.seed(43)\n","#np.random.shuffle(s)\n","\n","s_train, s_val = train_test_split(s, test_size=0.35, random_state=1)\n","#s_train, s_test = train_test_split(s_train, test_size=0.25, random_state=1)\n","\n","\n","ds_train = MyDataset(path,'Train',train_transform, s_train)\n","ds_val = MyDataset(path,'Train',train_transform, s_val)\n","\n","\n","\n","\n","s=np.arange(12630)\n","np.random.seed(43)\n","np.random.shuffle(s)\n","ds_test = MyDataset(path,'Test',train_transform, s)\n","print(ds_train.names.shape)\n","print(ds_val.names.shape)\n","print(ds_test.names.shape)\n","\n","\n"],"execution_count":8,"outputs":[{"output_type":"stream","text":["(29406,)\n","(9803,)\n","(12630,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-9mm5iwLiyu7","executionInfo":{"status":"ok","timestamp":1605685799468,"user_tz":480,"elapsed":301,"user":{"displayName":"Mohammad Karimi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhscZnXMfUg_B5TiqiYQWTpwdoSQgf3KMBVqAvcdx0=s64","userId":"12774174295451066351"}}},"source":["num_epochs = 50\n","test_frequency = 5\n","batch_size = 64\n","\n","train_loader = torch.utils.data.DataLoader(dataset=ds_train,\n","                                               batch_size=batch_size, \n","                                               shuffle=True,\n","                                               num_workers=1)\n","\n","val_loader = torch.utils.data.DataLoader(dataset=ds_val,\n","                                               batch_size=batch_size, \n","                                               shuffle=True,\n","                                               num_workers=1)\n","\n","test_loader = torch.utils.data.DataLoader(dataset=ds_test,\n","                                               batch_size=batch_size, \n","                                               shuffle=False,\n","                                               num_workers=1)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"sD4LQUtHAaJv","executionInfo":{"status":"ok","timestamp":1605685801885,"user_tz":480,"elapsed":310,"user":{"displayName":"Mohammad Karimi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhscZnXMfUg_B5TiqiYQWTpwdoSQgf3KMBVqAvcdx0=s64","userId":"12774174295451066351"}}},"source":["def get_lr(optimizer):\n","    for param_group in optimizer.param_groups:\n","        return param_group['lr']"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"F_3muTJoETW4","executionInfo":{"status":"ok","timestamp":1605685804868,"user_tz":480,"elapsed":618,"user":{"displayName":"Mohammad Karimi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhscZnXMfUg_B5TiqiYQWTpwdoSQgf3KMBVqAvcdx0=s64","userId":"12774174295451066351"}}},"source":["criterion = nn.MultiLabelSoftMarginLoss()"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"qZ8JF2ZI7dv8","executionInfo":{"status":"ok","timestamp":1605687448260,"user_tz":480,"elapsed":1385,"user":{"displayName":"Mohammad Karimi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhscZnXMfUg_B5TiqiYQWTpwdoSQgf3KMBVqAvcdx0=s64","userId":"12774174295451066351"}}},"source":["if 1:\n","  # Load Pretrained AlexNet\n","  classifier = torchvision.models.alexnet(pretrained=True)\n","  classifier.classifier._modules['6'] = nn.Linear(4096, num_classes)   \n","  classifier = classifier.to(device)\n","  optimizer = torch.optim.SGD(classifier.parameters(), lr=0.03, momentum=0.9)\n","  criterion = nn.MultiLabelSoftMarginLoss()"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"ybxSzwRS7fXl","executionInfo":{"status":"ok","timestamp":1605685820319,"user_tz":480,"elapsed":454,"user":{"displayName":"Mohammad Karimi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhscZnXMfUg_B5TiqiYQWTpwdoSQgf3KMBVqAvcdx0=s64","userId":"12774174295451066351"}}},"source":["if 0:\n","  classifier.load_state_dict(torch.load('./classifier.pth'))"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"h4KIH9zgiyu9","executionInfo":{"status":"error","timestamp":1605687422853,"user_tz":480,"elapsed":1590037,"user":{"displayName":"Mohammad Karimi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhscZnXMfUg_B5TiqiYQWTpwdoSQgf3KMBVqAvcdx0=s64","userId":"12774174295451066351"}},"outputId":"04f08ed4-1f15-4f81-809f-ad6c5d67f958","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["if 1:\n","  # TODO: Run your own classifier here\n","  #classifier = SimpleClassifier().to(device)\n","  # optimizer = torch.optim.SGD(classifier.parameters(), lr=0.01, momentum=0.9)\n","  # criterion = nn.MultiLabelSoftMarginLoss()\n","\n","\n","\n","\n","  #optimizer = torch.optim.SGD(classifier.parameters(), lr=0.01, momentum=0.9, weight_decay = 0.9)\n","  #optimizer = torch.optim.Adam(classifier.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n","\n","\n","  #decayRate = 0.97\n","  #lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=decayRate)\n","  # optimizer = torch.optim.Adam(classifier.parameters(), lr=1e-4)\n","\n","  classifier, train_losses, val_losses, train_mAPs, val_mAPs = train(classifier, num_epochs, train_loader, val_loader, criterion, optimizer, test_frequency)\n","\n","  torch.save(classifier.state_dict(), './classifier.pth')"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Starting epoch number 1\n","Loss for Training on Epoch 1 is 0.06389346718788147\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py:677: RuntimeWarning: invalid value encountered in true_divide\n","  recall = tps / tps[-1]\n"],"name":"stderr"},{"output_type":"stream","text":["-------  Class: 0                AP:   0.8050  -------\n","-------  Class: 1                AP:   0.9290  -------\n","-------  Class: 2                AP:   0.8834  -------\n","-------  Class: 3                AP:   0.8695  -------\n","-------  Class: 4                AP:   0.9322  -------\n","-------  Class: 5                AP:   0.7356  -------\n","-------  Class: 6                AP:   0.9978  -------\n","-------  Class: 7                AP:   0.8517  -------\n","-------  Class: 8                AP:   0.7875  -------\n","-------  Class: 9                AP:   0.9768  -------\n","-------  Class: 10               AP:   0.9915  -------\n","-------  Class: 11               AP:   0.9760  -------\n","-------  Class: 12               AP:   1.0000  -------\n","-------  Class: 13               AP:   0.9991  -------\n","-------  Class: 14               AP:   0.9997  -------\n","-------  Class: 15               AP:   0.9986  -------\n","-------  Class: 16               AP:   0.9948  -------\n","-------  Class: 17               AP:   0.9997  -------\n","-------  Class: 18               AP:   0.9695  -------\n","-------  Class: 19               AP:   0.4532  -------\n","-------  Class: 20               AP:   0.8545  -------\n","-------  Class: 21               AP:   0.5298  -------\n","-------  Class: 22               AP:   0.9578  -------\n","-------  Class: 23               AP:   0.8743  -------\n","-------  Class: 24               AP:   0.8585  -------\n","-------  Class: 25               AP:   0.9377  -------\n","-------  Class: 26               AP:   0.9521  -------\n","-------  Class: 27               AP:   0.6542  -------\n","-------  Class: 28               AP:   0.7899  -------\n","-------  Class: 29               AP:   0.7936  -------\n","-------  Class: 30               AP:   0.9195  -------\n","-------  Class: 31               AP:   0.9786  -------\n","-------  Class: 32               AP:   0.8937  -------\n","-------  Class: 33               AP:   0.9418  -------\n","-------  Class: 34               AP:   0.8419  -------\n","-------  Class: 35               AP:   0.9742  -------\n","-------  Class: 36               AP:   0.6211  -------\n","-------  Class: 37               AP:   0.4980  -------\n","-------  Class: 38               AP:   0.9866  -------\n","-------  Class: 39               AP:   0.6638  -------\n","-------  Class: 40               AP:   0.9548  -------\n","-------  Class: 41               AP:   0.5984  -------\n","-------  Class: 42               AP:   0.8871  -------\n","-------  Class: red              AP:   1.0000  -------\n","-------  Class: blue             AP:   1.0000  -------\n","-------  Class: black            AP:   0.9999  -------\n","-------  Class: circle           AP:   1.0000  -------\n","-------  Class: triangle         AP:   1.0000  -------\n","-------  Class: blk cross line     AP:   0.9982  -------\n","-------  Class: number 8         AP:   0.7212  -------\n","-------  Class: number 2         AP:   0.9617  -------\n","-------  Class: number 1         AP:   0.9999  -------\n","-------  Class: number 0         AP:   0.9698  -------\n","-------  Class: two cars         AP:   0.9763  -------\n","-------  Class: car and truck     AP:      nan  -------\n","mAP: nan\n","Avg loss: 0.020901869583342756\n","Evaluating classifier\n","Mean Precision Score for Testing on Epoch 1 is nan\n","Starting epoch number 2\n","Loss for Training on Epoch 2 is 0.017738329246640205\n","Starting epoch number 3\n","Loss for Training on Epoch 3 is 0.009614793583750725\n","Starting epoch number 4\n","Loss for Training on Epoch 4 is 0.006594279780983925\n","Starting epoch number 5\n","Loss for Training on Epoch 5 is 0.0044752550311386585\n","-------  Class: 0                AP:   0.9918  -------\n","-------  Class: 1                AP:   0.9975  -------\n","-------  Class: 2                AP:   0.9947  -------\n","-------  Class: 3                AP:   0.9922  -------\n","-------  Class: 4                AP:   0.9990  -------\n","-------  Class: 5                AP:   0.9854  -------\n","-------  Class: 6                AP:   1.0000  -------\n","-------  Class: 7                AP:   0.9944  -------\n","-------  Class: 8                AP:   0.9952  -------\n","-------  Class: 9                AP:   1.0000  -------\n","-------  Class: 10               AP:   0.9999  -------\n","-------  Class: 11               AP:   0.9999  -------\n","-------  Class: 12               AP:   1.0000  -------\n","-------  Class: 13               AP:   0.9997  -------\n","-------  Class: 14               AP:   1.0000  -------\n","-------  Class: 15               AP:   1.0000  -------\n","-------  Class: 16               AP:   1.0000  -------\n","-------  Class: 17               AP:   1.0000  -------\n","-------  Class: 18               AP:   0.9999  -------\n","-------  Class: 19               AP:   0.9971  -------\n","-------  Class: 20               AP:   0.9999  -------\n","-------  Class: 21               AP:   0.9991  -------\n","-------  Class: 22               AP:   0.9997  -------\n","-------  Class: 23               AP:   0.9963  -------\n","-------  Class: 24               AP:   0.9948  -------\n","-------  Class: 25               AP:   0.9996  -------\n","-------  Class: 26               AP:   0.9998  -------\n","-------  Class: 27               AP:   0.9896  -------\n","-------  Class: 28               AP:   0.9982  -------\n","-------  Class: 29               AP:   0.9991  -------\n","-------  Class: 30               AP:   0.9890  -------\n","-------  Class: 31               AP:   0.9999  -------\n","-------  Class: 32               AP:   1.0000  -------\n","-------  Class: 33               AP:   1.0000  -------\n","-------  Class: 34               AP:   0.9999  -------\n","-------  Class: 35               AP:   0.9997  -------\n","-------  Class: 36               AP:   1.0000  -------\n","-------  Class: 37               AP:   1.0000  -------\n","-------  Class: 38               AP:   1.0000  -------\n","-------  Class: 39               AP:   1.0000  -------\n","-------  Class: 40               AP:   1.0000  -------\n","-------  Class: 41               AP:   0.9950  -------\n","-------  Class: 42               AP:   0.9998  -------\n","-------  Class: red              AP:   1.0000  -------\n","-------  Class: blue             AP:   1.0000  -------\n","-------  Class: black            AP:   1.0000  -------\n","-------  Class: circle           AP:   1.0000  -------\n","-------  Class: triangle         AP:   1.0000  -------\n","-------  Class: blk cross line     AP:   1.0000  -------\n","-------  Class: number 8         AP:   0.9932  -------\n","-------  Class: number 2         AP:   0.9982  -------\n","-------  Class: number 1         AP:   1.0000  -------\n","-------  Class: number 0         AP:   0.9998  -------\n","-------  Class: two cars         AP:   0.9998  -------\n","-------  Class: car and truck     AP:      nan  -------\n","mAP: nan\n","Avg loss: 0.002653146762848384\n","Evaluating classifier\n","Mean Precision Score for Testing on Epoch 5 is nan\n","Starting epoch number 6\n","Loss for Training on Epoch 6 is 0.003694085171446204\n","Starting epoch number 7\n","Loss for Training on Epoch 7 is 0.00291098328307271\n","Starting epoch number 8\n","Loss for Training on Epoch 8 is 0.002307543996721506\n","Starting epoch number 9\n","Loss for Training on Epoch 9 is 0.0020229315850883722\n","Starting epoch number 10\n","Loss for Training on Epoch 10 is 0.001710564480163157\n","-------  Class: 0                AP:   1.0000  -------\n","-------  Class: 1                AP:   0.9998  -------\n","-------  Class: 2                AP:   0.9991  -------\n","-------  Class: 3                AP:   0.9965  -------\n","-------  Class: 4                AP:   0.9995  -------\n","-------  Class: 5                AP:   0.9966  -------\n","-------  Class: 6                AP:   1.0000  -------\n","-------  Class: 7                AP:   0.9978  -------\n","-------  Class: 8                AP:   0.9988  -------\n","-------  Class: 9                AP:   1.0000  -------\n","-------  Class: 10               AP:   1.0000  -------\n","-------  Class: 11               AP:   0.9999  -------\n","-------  Class: 12               AP:   1.0000  -------\n","-------  Class: 13               AP:   0.9998  -------\n","-------  Class: 14               AP:   1.0000  -------\n","-------  Class: 15               AP:   1.0000  -------\n","-------  Class: 16               AP:   1.0000  -------\n","-------  Class: 17               AP:   1.0000  -------\n","-------  Class: 18               AP:   1.0000  -------\n","-------  Class: 19               AP:   1.0000  -------\n","-------  Class: 20               AP:   0.9999  -------\n","-------  Class: 21               AP:   1.0000  -------\n","-------  Class: 22               AP:   1.0000  -------\n","-------  Class: 23               AP:   0.9995  -------\n","-------  Class: 24               AP:   0.9978  -------\n","-------  Class: 25               AP:   0.9999  -------\n","-------  Class: 26               AP:   1.0000  -------\n","-------  Class: 27               AP:   0.9979  -------\n","-------  Class: 28               AP:   1.0000  -------\n","-------  Class: 29               AP:   0.9993  -------\n","-------  Class: 30               AP:   0.9918  -------\n","-------  Class: 31               AP:   1.0000  -------\n","-------  Class: 32               AP:   1.0000  -------\n","-------  Class: 33               AP:   1.0000  -------\n","-------  Class: 34               AP:   1.0000  -------\n","-------  Class: 35               AP:   1.0000  -------\n","-------  Class: 36               AP:   1.0000  -------\n","-------  Class: 37               AP:   1.0000  -------\n","-------  Class: 38               AP:   1.0000  -------\n","-------  Class: 39               AP:   1.0000  -------\n","-------  Class: 40               AP:   1.0000  -------\n","-------  Class: 41               AP:   1.0000  -------\n","-------  Class: 42               AP:   1.0000  -------\n","-------  Class: red              AP:   1.0000  -------\n","-------  Class: blue             AP:   1.0000  -------\n","-------  Class: black            AP:   1.0000  -------\n","-------  Class: circle           AP:   1.0000  -------\n","-------  Class: triangle         AP:   1.0000  -------\n","-------  Class: blk cross line     AP:   1.0000  -------\n","-------  Class: number 8         AP:   0.9991  -------\n","-------  Class: number 2         AP:   0.9989  -------\n","-------  Class: number 1         AP:   1.0000  -------\n","-------  Class: number 0         AP:   1.0000  -------\n","-------  Class: two cars         AP:   1.0000  -------\n","-------  Class: car and truck     AP:      nan  -------\n","mAP: nan\n","Avg loss: 0.0013316898557014293\n","Evaluating classifier\n","Mean Precision Score for Testing on Epoch 10 is nan\n","Starting epoch number 11\n","Loss for Training on Epoch 11 is 0.0015134173445403576\n","Starting epoch number 12\n","Loss for Training on Epoch 12 is 0.0013102989178150892\n","Starting epoch number 13\n","Loss for Training on Epoch 13 is 0.0012260132934898138\n","Starting epoch number 14\n","Loss for Training on Epoch 14 is 0.0010633609490469098\n","Starting epoch number 15\n","Loss for Training on Epoch 15 is 0.0009930261876434088\n","-------  Class: 0                AP:   1.0000  -------\n","-------  Class: 1                AP:   0.9998  -------\n","-------  Class: 2                AP:   0.9998  -------\n","-------  Class: 3                AP:   0.9977  -------\n","-------  Class: 4                AP:   0.9998  -------\n","-------  Class: 5                AP:   0.9988  -------\n","-------  Class: 6                AP:   1.0000  -------\n","-------  Class: 7                AP:   0.9988  -------\n","-------  Class: 8                AP:   0.9999  -------\n","-------  Class: 9                AP:   1.0000  -------\n","-------  Class: 10               AP:   1.0000  -------\n","-------  Class: 11               AP:   1.0000  -------\n","-------  Class: 12               AP:   1.0000  -------\n","-------  Class: 13               AP:   0.9999  -------\n","-------  Class: 14               AP:   1.0000  -------\n","-------  Class: 15               AP:   1.0000  -------\n","-------  Class: 16               AP:   1.0000  -------\n","-------  Class: 17               AP:   1.0000  -------\n","-------  Class: 18               AP:   1.0000  -------\n","-------  Class: 19               AP:   1.0000  -------\n","-------  Class: 20               AP:   1.0000  -------\n","-------  Class: 21               AP:   1.0000  -------\n","-------  Class: 22               AP:   1.0000  -------\n","-------  Class: 23               AP:   0.9999  -------\n","-------  Class: 24               AP:   0.9982  -------\n","-------  Class: 25               AP:   1.0000  -------\n","-------  Class: 26               AP:   1.0000  -------\n","-------  Class: 27               AP:   0.9989  -------\n","-------  Class: 28               AP:   1.0000  -------\n","-------  Class: 29               AP:   1.0000  -------\n","-------  Class: 30               AP:   0.9974  -------\n","-------  Class: 31               AP:   1.0000  -------\n","-------  Class: 32               AP:   1.0000  -------\n","-------  Class: 33               AP:   1.0000  -------\n","-------  Class: 34               AP:   1.0000  -------\n","-------  Class: 35               AP:   1.0000  -------\n","-------  Class: 36               AP:   1.0000  -------\n","-------  Class: 37               AP:   1.0000  -------\n","-------  Class: 38               AP:   1.0000  -------\n","-------  Class: 39               AP:   1.0000  -------\n","-------  Class: 40               AP:   1.0000  -------\n","-------  Class: 41               AP:   1.0000  -------\n","-------  Class: 42               AP:   1.0000  -------\n","-------  Class: red              AP:   1.0000  -------\n","-------  Class: blue             AP:   1.0000  -------\n","-------  Class: black            AP:   1.0000  -------\n","-------  Class: circle           AP:   1.0000  -------\n","-------  Class: triangle         AP:   1.0000  -------\n","-------  Class: blk cross line     AP:   1.0000  -------\n","-------  Class: number 8         AP:   1.0000  -------\n","-------  Class: number 2         AP:   0.9997  -------\n","-------  Class: number 1         AP:   1.0000  -------\n","-------  Class: number 0         AP:   1.0000  -------\n","-------  Class: two cars         AP:   1.0000  -------\n","-------  Class: car and truck     AP:      nan  -------\n","mAP: nan\n","Avg loss: 0.0006841457880649873\n","Evaluating classifier\n","Mean Precision Score for Testing on Epoch 15 is nan\n","Starting epoch number 16\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-28e758ddae72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0;31m# optimizer = torch.optim.Adam(classifier.parameters(), lr=1e-4)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m   \u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_mAPs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_mAPs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_frequency\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'./classifier.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-5-4a314815641c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(classifier, num_epochs, train_loader, val_loader, criterion, optimizer, test_frequency)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting epoch number \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;31m#lr_scheduler.step()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-5-4a314815641c>\u001b[0m in \u001b[0;36mtrain_classifier\u001b[0;34m(train_loader, classifier, criterion, optimizer)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mloss_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    806\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 808\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    809\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                 \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"SjgDcuP8iyu_","executionInfo":{"status":"aborted","timestamp":1605687422851,"user_tz":480,"elapsed":1584953,"user":{"displayName":"Mohammad Karimi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhscZnXMfUg_B5TiqiYQWTpwdoSQgf3KMBVqAvcdx0=s64","userId":"12774174295451066351"}}},"source":["if 1:\n","  plot_losses(train_losses, val_losses, test_frequency, num_epochs)\n","  plot_mAP(train_mAPs, val_mAPs, test_frequency, num_epochs)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"m7ctwMnR2spr","executionInfo":{"status":"aborted","timestamp":1605687422852,"user_tz":480,"elapsed":1583250,"user":{"displayName":"Mohammad Karimi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhscZnXMfUg_B5TiqiYQWTpwdoSQgf3KMBVqAvcdx0=s64","userId":"12774174295451066351"}}},"source":["if 1:\n","  mAP_test, test_loss, test_aps = test_classifier(test_loader, classifier, criterion)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vA_mSgusr-Vt"},"source":["# Saving variables\n","This section I will save the variables in my session so I can process them later. I use Pickle to write and read."]},{"cell_type":"code","metadata":{"id":"h79wQA2ZsnbW"},"source":["file = open(\"./results.pkl\",'rb')\n","mAP_test, test_loss, test_aps, classifier = pickle.load(file)\n","file.close()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cDBAh6tcv8nx"},"source":["Save variables using pickle"]},{"cell_type":"code","metadata":{"id":"eG7_QRCkDxdr"},"source":["f = open(result_path + \"./MY_results.pkl\",\"wb\")\n","pickle.dump([train_losses, val_losses, train_mAPs, val_mAPs, classifier, test_frequency, num_epochs], f)\n","f.close()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fKP7EfGUvsPU"},"source":["read from pickle file"]},{"cell_type":"code","metadata":{"id":"tkP5nx1xk3xM"},"source":[" \n","# file = open(\"./results.pkl\", 'rb')\n","# train_losses, val_losses, train_mAPs, val_mAPs, classifier, test_frequency, num_epochs = pickle.load(file)\n","# file.close()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7f6_RlU3ht6a"},"source":["# Analysis of the results\n"]},{"cell_type":"markdown","metadata":{"id":"4i3ag3efst05"},"source":["## Regenerating the results\n","Lets re-generate the results for train\\val\\test datasets"]},{"cell_type":"code","metadata":{"id":"tUorzviBDNPh"},"source":["def classifier_output(test_loader, classifier):\n","    classifier.eval()\n","    with torch.no_grad():\n","        y_true = np.zeros((0,num_classes))\n","        y_score = np.zeros((0,num_classes))\n","        for i, (images, labels, _) in enumerate(test_loader):\n","            images, labels = images.to(device), labels.to(device)\n","            logits = classifier(images)\n","            y_true = np.concatenate((y_true, labels.cpu().numpy()), axis=0)\n","            y_score = np.concatenate((y_score, logits.cpu().numpy()), axis=0)\n","    return y_score, y_true"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SfcSpEeqljpS"},"source":["# mAP_train, train_loss, train_aps = test_classifier(train_loader, classifier, criterion)\n","\n","# mAP_val, val_loss, val_aps = test_classifier(val_loader, classifier, criterion)\n","\n","# mAP_test, test_loss, test_aps = test_classifier(test_loader, classifier, criterion)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jFiovDTErEPD"},"source":["train_output, train_target = classifier_output(train_loader, classifier)\n","val_output, val_target = classifier_output(val_loader, classifier)\n","test_output, test_target = classifier_output(test_loader, classifier)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tfIKF2nbj6G7"},"source":["f = open(result_path + \"./first_resp.pkl\",\"wb\")\n","pickle.dump([train_output, train_target, val_output, val_target, test_output, test_target], f)\n","f.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZvQ7421nkIwQ"},"source":["# file = open(\"./first_resp.pkl\", 'rb')\n","# train_output, train_target, val_output, val_target, test_output, test_target = pickle.load(file)\n","# file.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1ScKkEPniyvE"},"source":["# torch.save(classifier.state_dict(), './voc_my_best_classifier.pth')\n","# output_submission_csv('my_solution.csv', test_aps)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gLMbfHtaIeHN"},"source":["M = 702\n","print(train_output[M])\n","# print(train_logits[M])\n","\n","print(\"==========\")\n","print(train_target[M])\n","print(\"=======\")\n","for i,target in enumerate(train_target[M]):\n","  if target>0:\n","    print(i)\n","    print(train_output[M][i])\n","    # print(train_logits[M][i])\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cJJcYAGEjLP_","executionInfo":{"status":"ok","timestamp":1605672780042,"user_tz":480,"elapsed":266,"user":{"displayName":"Mohammad Karimi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhJ75pFAhL4LU1MeEMMbSjYBdYvZGdAXzHJiw-J=s64","userId":"06832749437853642271"}},"outputId":"f4bbc892-beed-422b-8e17-e70ce19bd2f2","colab":{"base_uri":"https://localhost:8080/"}},"source":["y_resp = np.zeros(train_output[1].shape)\n","y_resp[train_output[1]>0]=1\n","y_resp\n","print(y_resp)\n","print(train_target[1])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1.\n"," 0. 0. 0. 0. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1.\n"," 0. 0. 0. 0. 0. 0.]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"v6uPwElYiVEZ"},"source":["for i,target in enumerate(train_target):\n","  y_resp = np.zeros(train_output[i].shape)\n","  y_resp[train_output[i]>0]=1\n","  if target[:43]!=y_resp[:43]:\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"q95nRUg54hAs"},"source":["# Creating the second classifier\n","Here we create the second classifier to get the result from the first classifier with extended output and estimate 43 class of traffic signs.\n"]},{"cell_type":"markdown","metadata":{"id":"DMr1FSTL2HHQ"},"source":["defining the parameters:"]},{"cell_type":"code","metadata":{"id":"8H2VRtK_2GVS"},"source":["GTSRB_num_classes = 43\n","extInp_num_classes = num_classes"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zub0vz--1VIz"},"source":["defining a class to get the output of the first classifire. then we will give the output to the next_classifier"]},{"cell_type":"code","metadata":{"id":"HAb-71Vw086Q"},"source":["def next_train(classifier, num_epochs, train_loader, val_loader, criterion, optimizer, test_frequency=5):\n","    train_losses = []\n","    train_mAPs = []\n","    val_losses = []\n","    val_mAPs = []\n","    decayRate = 0.96\n","    \n","\n","    for epoch in range(1,num_epochs+1):\n","        print(\"Starting epoch number \" + str(epoch))\n","        train_loss = next_train_classifier(train_loader, classifier, criterion, optimizer)\n","        train_losses.append(train_loss)\n","        #lr_scheduler.step()\n","        #print('learning rate :', get_lr(lr_scheduler.optimizer))\n","\n","        print(\"Loss for Training on Epoch \" +str(epoch) + \" is \"+ str(train_loss))\n","        if(epoch%test_frequency==0 or epoch==1):\n","            mAP_train, _, _ = next_test_classifier(train_loader, classifier, criterion, False, False)\n","            train_mAPs.append(mAP_train)\n","            mAP_val, val_loss, _ = next_test_classifier(val_loader, classifier, criterion)\n","            print('Evaluating classifier')\n","            print(\"Mean Precision Score for Testing on Epoch \" +str(epoch) + \" is \"+ str(mAP_val))\n","            val_losses.append(val_loss)\n","            val_mAPs.append(mAP_val)\n","    \n","    return classifier, train_losses, val_losses, train_mAPs, val_mAPs\n","\n","def next_train_classifier(train_loader, classifier, criterion, optimizer):\n","    classifier.train()\n","    loss_ = 0.0\n","    losses = []\n","    for i, (input, labels) in enumerate(train_loader):\n","        input, labels = input.to(device), labels.to(device)\n","        optimizer.zero_grad()\n","        logits = classifier(input)\n","        loss = criterion(logits, labels)\n","        loss.backward()\n","        optimizer.step()\n","        losses.append(loss)\n","    return torch.stack(losses).mean().item()\n","\n","\n","def next_test_classifier(test_loader, classifier, criterion, print_ind_classes=True, print_total=True):\n","    classifier.eval()\n","    losses = []\n","    with torch.no_grad():\n","        y_true = np.zeros((0,GTSRB_num_classes))\n","        y_score = np.zeros((0,GTSRB_num_classes))\n","        for i, (input, labels) in enumerate(test_loader):\n","            input, labels = input.to(device), labels.to(device)\n","            logits = classifier(input)\n","            y_true = np.concatenate((y_true, labels.cpu().numpy()), axis=0)\n","            y_score = np.concatenate((y_score, logits.cpu().numpy()), axis=0)\n","            loss = criterion(logits, labels)\n","            losses.append(loss.item())\n","        aps = []\n","        # ignore first class which is background\n","        for i in range(0, y_true.shape[1]):\n","            ap = average_precision_score(y_true[:, i], y_score[:, i])\n","            if print_ind_classes:\n","                print('-------  Class: {:<12}     AP: {:>8.4f}  -------'.format(My_classes[i], ap))\n","            aps.append(ap)\n","        \n","        mAP = np.mean(aps)\n","        test_loss = np.mean(losses)\n","        if print_total:\n","            print('mAP: {0:.4f}'.format(mAP))\n","            print('Avg loss: {}'.format(test_loss))\n","        \n","    return mAP, test_loss, aps\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JzOu5cNw4gp7"},"source":["GTSRB_num_classes = 43\n","extInp_num_classes = num_classes\n","import torch.nn.functional as F\n","\n","\n","class next_classifier(nn.Module):\n","    def __init__(self):\n","        #super() allows you to build classes that easily extend the functionality of previously built classes without implementing their functionality again.\n","        super(next_classifier, self).__init__()\n","        self.fc1 = nn.Linear(in_features=extInp_num_classes, out_features=500, bias=True)\n","        self.fc2 = nn.Linear(in_features=500, out_features=500, bias=True)\n","        self.fc3 = nn.Linear(in_features=500, out_features=GTSRB_num_classes, bias=True)\n","        self.drop = nn.Dropout(p=0.2, inplace=False)\n","\n","    def forward(self, x):\n","        x = F.relu(self.fc1(x))\n","        x = self.drop(x)\n","        x = F.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8Diah73_d0a1"},"source":["import sys\n","import os, numpy as np\n","import torch\n","import torch.utils.data as data\n","\n","class NextDataset(data.Dataset):\n","    def __init__(self, input, labels):\n","        self.input = np.array(input).astype(np.float32)\n","        self.labels = np.array(labels).astype(np.float32)\n","        # self.num_trafficsigns = 43\n","\n","    def __getitem__(self, index):\n","        x = self.input[index]\n","        y = self.labels[index]\n","        return x, y\n","\n","    def __len__(self):\n","        return len(self.labels)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ICpt2kcyCRDn"},"source":["next_classifier = next_classifier().to(device)\n","optimizer = torch.optim.SGD(next_classifier.parameters(), lr=0.05, momentum=0.9)\n","criterion = nn.MultiLabelSoftMarginLoss()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MVPfzwbMARDZ"},"source":["Normalize the data here:\n"]},{"cell_type":"code","metadata":{"id":"VkmX4WE6AT3J"},"source":["train_output_n = train_output/100\n","val_output_n = val_output/100\n","test_output_n = test_output/100"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LeDehAr8eEz8"},"source":["ds_next_train = NextDataset(np.array(train_output_n).astype(np.float32), np.array(train_target[:,:43]).astype(np.float32))\n","ds_next_val = NextDataset(np.array(val_output_n).astype(np.float32), np.array(val_target[:,:43]).astype(np.float32))\n","ds_next_test = NextDataset(np.array(test_output_n).astype(np.float32), np.array(test_target[:,:43]).astype(np.float32))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3B3XExRjWNHY"},"source":["\n","\n","num_epochs = 5\n","test_frequency = 5\n","batch_size = 64\n","\n","next_train_loader = torch.utils.data.DataLoader(dataset=ds_next_train,\n","                                               batch_size=batch_size, \n","                                               shuffle=False,\n","                                               num_workers=1)\n","\n","next_val_loader = torch.utils.data.DataLoader(dataset=ds_next_val,\n","                                               batch_size=batch_size, \n","                                               shuffle=False,\n","                                               num_workers=1)\n","\n","next_test_loader = torch.utils.data.DataLoader(dataset=ds_next_test,\n","                                               batch_size=batch_size, \n","                                               shuffle=False,\n","                                               num_workers=1)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oOxL1YLHLQ5z","executionInfo":{"status":"ok","timestamp":1605665002542,"user_tz":480,"elapsed":15270,"user":{"displayName":"Mohammad Karimi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhJ75pFAhL4LU1MeEMMbSjYBdYvZGdAXzHJiw-J=s64","userId":"06832749437853642271"}},"outputId":"4172062d-b65c-40c4-e4fa-e063a0541f93","colab":{"base_uri":"https://localhost:8080/"}},"source":["next_classifier, train_losses_1, val_losses_1, train_mAPs_1, val_mAPs_1 = next_train(next_classifier, num_epochs, next_train_loader, next_val_loader, criterion, optimizer, test_frequency)\n","\n","torch.save(classifier.state_dict(), './classifier2.pth')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Starting epoch number 1\n","Loss for Training on Epoch 1 is 0.003346209181472659\n","-------  Class: 0                AP:   0.9913  -------\n","-------  Class: 1                AP:   0.9970  -------\n","-------  Class: 2                AP:   0.9969  -------\n","-------  Class: 3                AP:   0.9989  -------\n","-------  Class: 4                AP:   0.9997  -------\n","-------  Class: 5                AP:   0.9958  -------\n","-------  Class: 6                AP:   1.0000  -------\n","-------  Class: 7                AP:   0.9973  -------\n","-------  Class: 8                AP:   0.9994  -------\n","-------  Class: 9                AP:   1.0000  -------\n","-------  Class: 10               AP:   1.0000  -------\n","-------  Class: 11               AP:   0.9988  -------\n","-------  Class: 12               AP:   1.0000  -------\n","-------  Class: 13               AP:   0.9994  -------\n","-------  Class: 14               AP:   1.0000  -------\n","-------  Class: 15               AP:   0.9982  -------\n","-------  Class: 16               AP:   1.0000  -------\n","-------  Class: 17               AP:   1.0000  -------\n","-------  Class: 18               AP:   1.0000  -------\n","-------  Class: 19               AP:   0.8067  -------\n","-------  Class: 20               AP:   0.8940  -------\n","-------  Class: 21               AP:   0.9940  -------\n","-------  Class: 22               AP:   0.9999  -------\n","-------  Class: 23               AP:   0.9940  -------\n","-------  Class: 24               AP:   0.9988  -------\n","-------  Class: 25               AP:   0.9999  -------\n","-------  Class: 26               AP:   1.0000  -------\n","-------  Class: 27               AP:   1.0000  -------\n","-------  Class: 28               AP:   0.9908  -------\n","-------  Class: 29               AP:   0.9757  -------\n","-------  Class: 30               AP:   0.9866  -------\n","-------  Class: 31               AP:   1.0000  -------\n","-------  Class: 32               AP:   0.9997  -------\n","-------  Class: 33               AP:   0.9895  -------\n","-------  Class: 34               AP:   0.9203  -------\n","-------  Class: 35               AP:   1.0000  -------\n","-------  Class: 36               AP:   0.9509  -------\n","-------  Class: 37               AP:   0.8565  -------\n","-------  Class: 38               AP:   0.9994  -------\n","-------  Class: 39               AP:   0.9450  -------\n","-------  Class: 40               AP:   0.9959  -------\n","-------  Class: 41               AP:   0.9992  -------\n","-------  Class: 42               AP:   1.0000  -------\n","mAP: 0.9830\n","Avg loss: 0.0032063743255294668\n","Evaluating classifier\n","Mean Precision Score for Testing on Epoch 1 is 0.9830115940114361\n","Starting epoch number 2\n","Loss for Training on Epoch 2 is 0.003325893310829997\n","Starting epoch number 3\n","Loss for Training on Epoch 3 is 0.003293283050879836\n","Starting epoch number 4\n","Loss for Training on Epoch 4 is 0.003302160417661071\n","Starting epoch number 5\n","Loss for Training on Epoch 5 is 0.003249534871429205\n","-------  Class: 0                AP:   0.9910  -------\n","-------  Class: 1                AP:   0.9971  -------\n","-------  Class: 2                AP:   0.9970  -------\n","-------  Class: 3                AP:   0.9989  -------\n","-------  Class: 4                AP:   0.9997  -------\n","-------  Class: 5                AP:   0.9959  -------\n","-------  Class: 6                AP:   1.0000  -------\n","-------  Class: 7                AP:   0.9972  -------\n","-------  Class: 8                AP:   0.9994  -------\n","-------  Class: 9                AP:   1.0000  -------\n","-------  Class: 10               AP:   1.0000  -------\n","-------  Class: 11               AP:   0.9989  -------\n","-------  Class: 12               AP:   1.0000  -------\n","-------  Class: 13               AP:   0.9994  -------\n","-------  Class: 14               AP:   1.0000  -------\n","-------  Class: 15               AP:   0.9983  -------\n","-------  Class: 16               AP:   1.0000  -------\n","-------  Class: 17               AP:   1.0000  -------\n","-------  Class: 18               AP:   1.0000  -------\n","-------  Class: 19               AP:   0.8107  -------\n","-------  Class: 20               AP:   0.8972  -------\n","-------  Class: 21               AP:   0.9950  -------\n","-------  Class: 22               AP:   0.9999  -------\n","-------  Class: 23               AP:   0.9943  -------\n","-------  Class: 24               AP:   0.9988  -------\n","-------  Class: 25               AP:   0.9999  -------\n","-------  Class: 26               AP:   1.0000  -------\n","-------  Class: 27               AP:   1.0000  -------\n","-------  Class: 28               AP:   0.9911  -------\n","-------  Class: 29               AP:   0.9758  -------\n","-------  Class: 30               AP:   0.9869  -------\n","-------  Class: 31               AP:   1.0000  -------\n","-------  Class: 32               AP:   0.9997  -------\n","-------  Class: 33               AP:   0.9905  -------\n","-------  Class: 34               AP:   0.9235  -------\n","-------  Class: 35               AP:   1.0000  -------\n","-------  Class: 36               AP:   0.9559  -------\n","-------  Class: 37               AP:   0.8705  -------\n","-------  Class: 38               AP:   0.9995  -------\n","-------  Class: 39               AP:   0.9493  -------\n","-------  Class: 40               AP:   0.9962  -------\n","-------  Class: 41               AP:   0.9992  -------\n","-------  Class: 42               AP:   1.0000  -------\n","mAP: 0.9839\n","Avg loss: 0.003116121457424015\n","Evaluating classifier\n","Mean Precision Score for Testing on Epoch 5 is 0.983873557983318\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UA2Xjk2Adys0","executionInfo":{"status":"ok","timestamp":1605665005766,"user_tz":480,"elapsed":1217,"user":{"displayName":"Mohammad Karimi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhJ75pFAhL4LU1MeEMMbSjYBdYvZGdAXzHJiw-J=s64","userId":"06832749437853642271"}},"outputId":"a0bd1c92-a484-4cc2-84d7-ed7208b487fc","colab":{"base_uri":"https://localhost:8080/"}},"source":["next_mAP_test, next_test_loss, next_test_aps = next_test_classifier(next_test_loader, next_classifier, criterion)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["-------  Class: 0                AP:   0.9932  -------\n","-------  Class: 1                AP:   0.9957  -------\n","-------  Class: 2                AP:   0.9932  -------\n","-------  Class: 3                AP:   0.9854  -------\n","-------  Class: 4                AP:   0.9901  -------\n","-------  Class: 5                AP:   0.9892  -------\n","-------  Class: 6                AP:   0.9679  -------\n","-------  Class: 7                AP:   0.9969  -------\n","-------  Class: 8                AP:   0.9911  -------\n","-------  Class: 9                AP:   0.9999  -------\n","-------  Class: 10               AP:   0.9999  -------\n","-------  Class: 11               AP:   0.9795  -------\n","-------  Class: 12               AP:   0.9990  -------\n","-------  Class: 13               AP:   0.9989  -------\n","-------  Class: 14               AP:   0.9996  -------\n","-------  Class: 15               AP:   0.9976  -------\n","-------  Class: 16               AP:   1.0000  -------\n","-------  Class: 17               AP:   0.9703  -------\n","-------  Class: 18               AP:   0.9780  -------\n","-------  Class: 19               AP:   0.5712  -------\n","-------  Class: 20               AP:   0.6257  -------\n","-------  Class: 21               AP:   0.6528  -------\n","-------  Class: 22               AP:   0.9806  -------\n","-------  Class: 23               AP:   0.9789  -------\n","-------  Class: 24               AP:   0.9992  -------\n","-------  Class: 25               AP:   0.9914  -------\n","-------  Class: 26               AP:   0.9712  -------\n","-------  Class: 27               AP:   0.8690  -------\n","-------  Class: 28               AP:   0.9976  -------\n","-------  Class: 29               AP:   0.9629  -------\n","-------  Class: 30               AP:   0.9444  -------\n","-------  Class: 31               AP:   0.9982  -------\n","-------  Class: 32               AP:   0.9975  -------\n","-------  Class: 33               AP:   0.8928  -------\n","-------  Class: 34               AP:   0.8345  -------\n","-------  Class: 35               AP:   0.9686  -------\n","-------  Class: 36               AP:   0.5909  -------\n","-------  Class: 37               AP:   0.4939  -------\n","-------  Class: 38               AP:   0.9406  -------\n","-------  Class: 39               AP:   0.6503  -------\n","-------  Class: 40               AP:   0.8392  -------\n","-------  Class: 41               AP:   0.9947  -------\n","-------  Class: 42               AP:   0.8971  -------\n","mAP: 0.9179\n","Avg loss: 0.009906295844532474\n"],"name":"stdout"}]}]}