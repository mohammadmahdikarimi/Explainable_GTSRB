{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Top_GTSRB.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"}},"cells":[{"cell_type":"markdown","metadata":{"id":"YYXJwJMwiyun"},"source":["# Assignment 3 Part 1: Developing Your Own Classifier"]},{"cell_type":"code","metadata":{"id":"Q6YDS3Thleh5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605754884795,"user_tz":480,"elapsed":657,"user":{"displayName":"Mohammad Karimi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhscZnXMfUg_B5TiqiYQWTpwdoSQgf3KMBVqAvcdx0=s64","userId":"12774174295451066351"}},"outputId":"5dcf5a3d-c3a0-4abe-b0af-ea367fa6c89a"},"source":["import os\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=False)\n","os.chdir(\"/content/drive/My Drive/A-Courses-PhD/Term_17_Fall2020/CS498-DL/assignments/Project/Explainable_GTSRB\")\n","#os.chdir(\"/content/drive/My Drive/CS498-DL/assignments/Assignment_03/My_assignment3_p1_starterkit\")\n"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"flUDGBpmJbmG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605754887204,"user_tz":480,"elapsed":3052,"user":{"displayName":"Mohammad Karimi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhscZnXMfUg_B5TiqiYQWTpwdoSQgf3KMBVqAvcdx0=s64","userId":"12774174295451066351"}},"outputId":"09864d6e-a664-4fdf-e6f4-5495f2dea849"},"source":["!pip install torch==1.4.0 torchvision==0.5.0\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: torch==1.4.0 in /usr/local/lib/python3.6/dist-packages (1.4.0)\n","Requirement already satisfied: torchvision==0.5.0 in /usr/local/lib/python3.6/dist-packages (0.5.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision==0.5.0) (1.15.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==0.5.0) (1.18.5)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.5.0) (7.0.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GaOqSjzxiyup","executionInfo":{"status":"ok","timestamp":1605754887950,"user_tz":480,"elapsed":3790,"user":{"displayName":"Mohammad Karimi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhscZnXMfUg_B5TiqiYQWTpwdoSQgf3KMBVqAvcdx0=s64","userId":"12774174295451066351"}}},"source":["import os\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torchvision\n","\n","import PIL\n","from torchvision import transforms\n","from sklearn.metrics import average_precision_score\n","from PIL import Image, ImageDraw\n","import matplotlib.pyplot as plt\n","#from kaggle_submission import output_submission_csv\n","from classifier import SimpleClassifier, Classifier, Classifier_moreConv#, AlexNet\n","#from voc_dataloader import VocDataset, VOC_CLASSES\n","#from dataloader import MyDataset, My_classes\n","import pickle\n","\n","from sklearn.model_selection import train_test_split\n","\n","%matplotlib inline\n","%load_ext autoreload\n","%autoreload 2\n","\n","path ='/content/GTSRB_data/'\n","#path = 'G:/My Drive/A-Courses-PhD/Term_17_Fall2020/CS498-DL/assignments/Project/gtsrb-german-traffic-sign/GTSRB_data'\n","# num_classes = len(My_classes)\n","result_path = ''"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"b6g5m8ZxKESG","executionInfo":{"status":"ok","timestamp":1605754892711,"user_tz":480,"elapsed":8542,"user":{"displayName":"Mohammad Karimi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhscZnXMfUg_B5TiqiYQWTpwdoSQgf3KMBVqAvcdx0=s64","userId":"12774174295451066351"}}},"source":["if 1:\n","  import shutil \n","  shutil.copyfile(\"GTSRB_data.tar\", \"/content/GTSRB_data.tar\")\n","  !tar -xf \"/content/GTSRB_data.tar\" -C \"/content/\" \n","  #shutil.move(\"/content/VOCdevkit/\", \"/content/VOCdevkit_2007\")\n"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"S4Chtrwviyus"},"source":["# Part 1B: Design your own network\n","\n","In this notebook, your task is to create and train your own model for multi-label classification on VOC Pascal.\n","\n","## What to do\n","1. You will make change on network architecture in ```classifier.py```.\n","2. You may also want to change other hyperparameters to assist your training to get a better performances. Hints will be given in the below instructions.\n","\n","## What to submit\n","Check the submission template for details what to submit. "]},{"cell_type":"code","metadata":{"id":"bCcQkmp4iyuv","executionInfo":{"status":"ok","timestamp":1605754892844,"user_tz":480,"elapsed":8668,"user":{"displayName":"Mohammad Karimi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhscZnXMfUg_B5TiqiYQWTpwdoSQgf3KMBVqAvcdx0=s64","userId":"12774174295451066351"}}},"source":["def train_classifier(train_loader, classifier, criterion, optimizer):\n","    classifier.train()\n","    loss_ = 0.0\n","    losses = []\n","    for i, (images, labels, _) in enumerate(train_loader):\n","        images, labels = images.to(device), labels.to(device)\n","        optimizer.zero_grad()\n","        logits = classifier(images)\n","        loss = criterion(logits, labels)\n","        loss.backward()\n","        optimizer.step()\n","        losses.append(loss)\n","    return torch.stack(losses).mean().item()\n","\n","def test_classifier(test_loader, classifier, criterion, print_ind_classes=True, print_total=True):\n","    classifier.eval()\n","    losses = []\n","    with torch.no_grad():\n","        y_true = np.zeros((0,num_classes))\n","        y_score = np.zeros((0,num_classes))\n","        for i, (images, labels, _) in enumerate(test_loader):\n","            images, labels = images.to(device), labels.to(device)\n","            logits = classifier(images)\n","            y_true = np.concatenate((y_true, labels.cpu().numpy()), axis=0)\n","            y_score = np.concatenate((y_score, logits.cpu().numpy()), axis=0)\n","            loss = criterion(logits, labels)\n","            losses.append(loss.item())\n","        aps = []\n","        for i in range(0, y_true.shape[1]):\n","            ap = average_precision_score(y_true[:, i], y_score[:, i])\n","            if print_ind_classes:\n","                print('-------  Class: {:<12}     AP: {:>8.4f}  -------'.format(My_classes[i], ap))\n","            aps.append(ap)\n","        \n","        mAP = np.mean(aps)\n","        test_loss = np.mean(losses)\n","        if print_total:\n","            print('mAP: {0:.4f}'.format(mAP))\n","            print('Avg loss: {}'.format(test_loss))\n","        \n","    return mAP, test_loss, aps\n","\n","def plot_losses(train, val, test_frequency, num_epochs):\n","    plt.plot(train, label=\"train\")\n","    indices = [i for i in range(num_epochs) if ((i+1)%test_frequency == 0 or i ==0)]\n","    plt.plot(indices, val, label=\"val\")\n","    plt.title(\"Loss Plot\")\n","    plt.ylabel(\"Loss\")\n","    plt.xlabel(\"Epoch\")\n","    plt.legend()\n","    plt.show()\n","    \n","def plot_mAP(train, val, test_frequency, num_epochs):\n","    indices = [i for i in range(num_epochs) if ((i+1)%test_frequency == 0 or i ==0)]\n","    plt.plot(indices, train, label=\"train\")\n","    plt.plot(indices, val, label=\"val\")\n","    plt.title(\"mAP Plot\")\n","    plt.ylabel(\"mAP\")\n","    plt.xlabel(\"Epoch\")\n","    plt.legend()\n","    plt.show()\n","    \n","\n","def train(classifier, num_epochs, train_loader, val_loader, criterion, optimizer, test_frequency=5):\n","    train_losses = []\n","    train_mAPs = []\n","    val_losses = []\n","    val_mAPs = []\n","    decayRate = 0.96\n","    \n","\n","    for epoch in range(1,num_epochs+1):\n","        print(\"Starting epoch number \" + str(epoch))\n","        train_loss = train_classifier(train_loader, classifier, criterion, optimizer)\n","        train_losses.append(train_loss)\n","        #lr_scheduler.step()\n","        #print('learning rate :', get_lr(lr_scheduler.optimizer))\n","\n","        print(\"Loss for Training on Epoch \" +str(epoch) + \" is \"+ str(train_loss))\n","        if(epoch%test_frequency==0 or epoch==1):\n","            mAP_train, _, _ = test_classifier(train_loader, classifier, criterion, False, False)\n","            train_mAPs.append(mAP_train)\n","            mAP_val, val_loss, _ = test_classifier(val_loader, classifier, criterion)\n","            print('Evaluating classifier')\n","            print(\"Mean Precision Score for Testing on Epoch \" +str(epoch) + \" is \"+ str(mAP_val))\n","            val_losses.append(val_loss)\n","            val_mAPs.append(mAP_val)\n","    \n","    return classifier, train_losses, val_losses, train_mAPs, val_mAPs\n","\n","    "],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4HDJRrpBiyu3"},"source":["# Developing Your Own Model"]},{"cell_type":"markdown","metadata":{"id":"eENCD04wiyu3"},"source":["### Goal\n","To meet the benchmark for this assignment you will need to improve the network. Note you should have noticed pretrained Alenxt performs really well, but training Alexnet from scratch performs much worse. We hope you can design a better architecture over both the simple classifier and AlexNet to train from scratch.\n","\n","### How to start\n","You may take inspiration from other published architectures and architectures discussed in lecture. However, you are NOT allowed to use predefined models (e.g. models from torchvision) or use pretrained weights. Training must be done from scratch with your own custom model.\n","\n","#### Some hints\n","There are a variety of different approaches you should try to improve performance from the simple classifier:\n","\n","* Network architecture changes\n","    * Number of layers: try adding layers to make your network deeper\n","    * Batch normalization: adding batch norm between layers will likely give you a significant performance increase\n","    * Residual connections: as you increase the depth of your network, you will find that having residual connections like those in ResNet architectures will be helpful\n","* Optimizer: Instead of plain SGD, you may want to add a learning rate schedule, add momentum, or use one of the other optimizers you have learned about like Adam. Check the `torch.optim` package for other optimizers\n","* Data augmentation: You should use the `torchvision.transforms` module to try adding random resized crops and horizontal flips of the input data. Check `transforms.RandomResizedCrop` and `transforms.RandomHorizontalFlip` for this. Feel free to apply more [transforms](https://pytorch.org/docs/stable/torchvision/transforms.html) for data augmentation which can lead to better performance. \n","* Epochs: Once you have found a generally good hyperparameter setting try training for more epochs\n","* Loss function: You might want to add weighting to the `MultiLabelSoftMarginLoss` for classes that are less well represented or experiment with a different loss function\n","\n","\n","\n","#### Note\n","We will soon be providing some initial expectations of mAP values as a function of epoch so you can get an early idea whether your implementation works without waiting a long time for training to converge.\n","\n","### What to submit \n","Submit your best model to Kaggle and save all plots for the writeup.\n"]},{"cell_type":"code","metadata":{"id":"6HwbEiH_2XTd","executionInfo":{"status":"ok","timestamp":1605754892844,"user_tz":480,"elapsed":8662,"user":{"displayName":"Mohammad Karimi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhscZnXMfUg_B5TiqiYQWTpwdoSQgf3KMBVqAvcdx0=s64","userId":"12774174295451066351"}}},"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"4pyVJsYSiyu4","executionInfo":{"status":"ok","timestamp":1605754893034,"user_tz":480,"elapsed":8846,"user":{"displayName":"Mohammad Karimi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhscZnXMfUg_B5TiqiYQWTpwdoSQgf3KMBVqAvcdx0=s64","userId":"12774174295451066351"}}},"source":["\n","\n","normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                                     std= [0.229, 0.224, 0.225])\n","\n","train_transform = transforms.Compose([\n","            #torchvision.transforms.ColorJitter(hue=.1, saturation=.05),\n","            #torchvision.transforms.RandomHorizontalFlip(),\n","            #torchvision.transforms.RandomRotation(10, resample=PIL.Image.BILINEAR),\n","            transforms.Resize(227),\n","            transforms.CenterCrop(227),\n","            transforms.ToTensor(),\n","            normalize\n","        ])\n","\n","test_transform = transforms.Compose([\n","            transforms.Resize(227),\n","            transforms.CenterCrop(227),\n","            transforms.ToTensor(),\n","            normalize,\n","        ])\n","\n"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"xZxNQQeuVEjo","executionInfo":{"status":"ok","timestamp":1605754893205,"user_tz":480,"elapsed":9011,"user":{"displayName":"Mohammad Karimi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhscZnXMfUg_B5TiqiYQWTpwdoSQgf3KMBVqAvcdx0=s64","userId":"12774174295451066351"}}},"source":["import sys\n","#import random\n","import os, numpy as np\n","import torch\n","import torchvision.transforms as transforms\n","import torch.utils.data as data\n","#from skiage.transform import resize\n","#from scipy.sparse import csr_matrix\n","from PIL import Image\n","import xml.etree.ElementTree as ET\n","import csv\n","\n","#import cv2\n","\n","#import matplotlib.pyplot as plt\n","\n","\n","My_classes = []\n","Extended_cls = ('red', 'blue', 'black', 'circle', 'triangle',\n","                  'blk cross line', 'number 8','number 2', 'number 1', 'number 0',\n","                  'car and truck', 'two cars')\n","for i in range(43):\n","    My_classes.append(str(i))\n","for i in Extended_cls:\n","    My_classes.append(i)\n","\n","class MyDataset(data.Dataset):\n","    def __init__(self, data_path, dataset_split, transform, file_Indx, random_crops=0):\n","        self.data_path = data_path\n","        self.transform = transform   #data transformation, augmentation  #from torchvision import transforms\n","        self.random_crops = random_crops\n","        self.dataset_split = dataset_split  #train, val, test\n","        self.num_trafficsigns = 43\n","        self.file_Indx = file_Indx      #train/test/val are indexed from total image pool given here one by one\n","\n","        self.__init_classes()\n","        self.names, self.labels, self.box_indices, self.label_order = self.__dataset_info()\n","\n","    def __getitem__(self, index):\n","        # CHANGED\n","#         x = imread( self.names[index], mode='RGB')\n","#         x = Image.fromarray(x)\n","        x = Image.open(self.names[index])\n","\n","        scale = np.random.rand() * 2 + 0.25\n","        w = int(x.size[0] * scale)\n","        h = int(x.size[1] * scale)\n","        if min(w, h) < 227:\n","            scale = 227 / min(w, h)\n","            w = int(x.size[0] * scale)\n","            h = int(x.size[1] * scale)\n","\n","        if self.random_crops == 0:\n","            x = self.transform(x)\n","        else:\n","            crops = []\n","            for i in range(self.random_crops):\n","                crops.append(self.transform(x))\n","            x = torch.stack(crops)\n","\n","        y = self.labels[index]\n","        z = self.box_indices[index]\n","        return x, y, z\n","\n","    def __len__(self):\n","        return len(self.names)\n","\n","    def __init_classes(self):\n","        self.classes = My_classes\n","        self.num_classes = len(self.classes)  # 43 + len(additional classes)\n","        self.class_to_ind = dict(zip(self.classes, range(self.num_classes)))\n","\n","    def ex_cls(self):\n","        class_map = dict()\n","        for i in range(43):\n","            class_map[str(i)] = []\n","\n","        f_path = \"/content/drive/MyDrive/A-Courses-PhD/Term_17_Fall2020/CS498-DL/assignments/Project/Explainable_GTSRB/\"\n","        # print(f_path)\n","        with open(f_path + '/top_ex_cls.csv') as csv_file:\n","            csv_reader = csv.reader(csv_file)\n","            for i, line in enumerate(csv_reader):\n","                #print(\"line{}: {}\".format(i,line))\n","                if i !=0:\n","                    cls = [i for i, x in enumerate(line[1:]) if x == \"1\"]\n","                    class_map[str(line[0])] = cls\n"," \n","        return class_map\n","\n","\n","\n","    def __dataset_info(self):\n","\n","        img = dict()\n","        img['name'] = []\n","        img['box'] = []     #x1,,y1,x2,y2\n","        img['cls_id'] = []\n","        img['size'] = []    #width,height\n","        img['label_order'] = []\n","        img['labels'] = []\n","        class_map = self.ex_cls()\n","        with open(self.data_path + '/ImageSets/Main/' + self.dataset_split + '.csv') as csv_file:\n","            csv_reader = csv.DictReader(csv_file)\n","            for line in csv_reader:\n","                img['cls_id'].append(line['ClassId'])\n","                img['size'].append([line['Width'], line['Height']])\n","                img['name'].append(os.path.join(self.data_path, line['Path']))\n","\n","                # Make pixel indexes 0-based\n","                x1 = float(line['Roi.X1']) - 1\n","                y1 = float(line['Roi.Y1']) - 1\n","                x2 = float(line['Roi.X2']) - 1\n","                y2 = float(line['Roi.Y2']) - 1\n","                img['box'].append([x1, y1, x2, y2])\n","                # if line['ClassId'] == '9':\n","                #     print('this')\n","                #     print(line['ClassId'])\n","                #     print(class_map[line['ClassId']])\n","                img['label_order'].append(class_map[line['ClassId']])\n","\n","                lbl = np.zeros(self.num_classes)\n","                lbl[class_map[line['ClassId']]] = 1\n","                img['labels'].append(lbl)\n","        dum = 0\n","        return np.array(img['name'])[self.file_Indx], np.array(img['labels']).astype(np.float32)[self.file_Indx], np.array(img['box'])[self.file_Indx], np.array(img['label_order'])[self.file_Indx]\n"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"E_ZYj8PNJWs6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605754894591,"user_tz":480,"elapsed":10391,"user":{"displayName":"Mohammad Karimi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhscZnXMfUg_B5TiqiYQWTpwdoSQgf3KMBVqAvcdx0=s64","userId":"12774174295451066351"}},"outputId":"a4abd743-e0e3-4a4c-9b33-88ec1b3948c2"},"source":["num_classes = len(My_classes)\n","#Randomize the order of the input images\n","#s=np.arange(ds_train.names.shape[0])\n","s=np.arange(39209)\n","np.random.seed(43)\n","np.random.shuffle(s)\n","# s=s[:500]\n","s_train, s_val = train_test_split(s, test_size=0.3, random_state=1)\n","#s_train, s_test = train_test_split(s_train, test_size=0.25, random_state=1)\n","\n","\n","ds_train = MyDataset(path,'Train',train_transform, s_train)\n","ds_val = MyDataset(path,'Train',train_transform, s_val)\n","\n","\n","\n","\n","s_test=np.arange(12630)\n","np.random.seed(43)\n","np.random.shuffle(s_test)\n","ds_test = MyDataset(path,'Test',train_transform, s_test)\n","print(ds_train.names.shape)\n","print(ds_val.names.shape)\n","print(ds_test.names.shape)\n","\n"],"execution_count":9,"outputs":[{"output_type":"stream","text":["(27446,)\n","(11763,)\n","(12630,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-9mm5iwLiyu7","executionInfo":{"status":"ok","timestamp":1605754894592,"user_tz":480,"elapsed":10379,"user":{"displayName":"Mohammad Karimi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhscZnXMfUg_B5TiqiYQWTpwdoSQgf3KMBVqAvcdx0=s64","userId":"12774174295451066351"}}},"source":["num_epochs = 15\n","test_frequency = 1\n","batch_size = 64\n","\n","train_loader = torch.utils.data.DataLoader(dataset=ds_train,\n","                                               batch_size=batch_size, \n","                                               shuffle=True,\n","                                               num_workers=1)\n","\n","val_loader = torch.utils.data.DataLoader(dataset=ds_val,\n","                                               batch_size=batch_size, \n","                                               shuffle=True,\n","                                               num_workers=1)\n","\n","test_loader = torch.utils.data.DataLoader(dataset=ds_test,\n","                                               batch_size=batch_size, \n","                                               shuffle=False,\n","                                               num_workers=1)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"sD4LQUtHAaJv","executionInfo":{"status":"ok","timestamp":1605754894592,"user_tz":480,"elapsed":10367,"user":{"displayName":"Mohammad Karimi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhscZnXMfUg_B5TiqiYQWTpwdoSQgf3KMBVqAvcdx0=s64","userId":"12774174295451066351"}}},"source":["def get_lr(optimizer):\n","    for param_group in optimizer.param_groups:\n","        return param_group['lr']"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"F_3muTJoETW4","executionInfo":{"status":"ok","timestamp":1605754894593,"user_tz":480,"elapsed":10359,"user":{"displayName":"Mohammad Karimi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhscZnXMfUg_B5TiqiYQWTpwdoSQgf3KMBVqAvcdx0=s64","userId":"12774174295451066351"}}},"source":["criterion = nn.MultiLabelSoftMarginLoss()"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"qZ8JF2ZI7dv8","executionInfo":{"status":"ok","timestamp":1605755024086,"user_tz":480,"elapsed":1622,"user":{"displayName":"Mohammad Karimi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhscZnXMfUg_B5TiqiYQWTpwdoSQgf3KMBVqAvcdx0=s64","userId":"12774174295451066351"}}},"source":["if 1:\n","  # Load Pretrained AlexNet\n","  classifier = torchvision.models.alexnet(pretrained=True)\n","  classifier.classifier._modules['6'] = nn.Linear(4096, num_classes)   \n","  classifier = classifier.to(device)\n","  optimizer = torch.optim.SGD(classifier.parameters(), lr=0.03, momentum=0.9)\n","  criterion = nn.MultiLabelSoftMarginLoss()"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"ybxSzwRS7fXl","executionInfo":{"status":"ok","timestamp":1605754899896,"user_tz":480,"elapsed":15643,"user":{"displayName":"Mohammad Karimi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhscZnXMfUg_B5TiqiYQWTpwdoSQgf3KMBVqAvcdx0=s64","userId":"12774174295451066351"}}},"source":["if 0:\n","  classifier.load_state_dict(torch.load('./classifier.pth'))"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"h4KIH9zgiyu9","colab":{"base_uri":"https://localhost:8080/"},"outputId":"4391001c-31f7-44c1-a868-760f5b3ffe1e"},"source":["if 1:\n","  # TODO: Run your own classifier here\n","  # classifier = SimpleClassifier().to(device)\n","  # optimizer = torch.optim.SGD(classifier.parameters(), lr=0.01, momentum=0.9)\n","  # criterion = nn.MultiLabelSoftMarginLoss()\n","\n","\n","\n","\n","  #optimizer = torch.optim.SGD(classifier.parameters(), lr=0.01, momentum=0.9, weight_decay = 0.9)\n","  #optimizer = torch.optim.Adam(classifier.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n","\n","\n","  #decayRate = 0.97\n","  #lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=decayRate)\n","  # optimizer = torch.optim.Adam(classifier.parameters(), lr=1e-4)\n","\n","  classifier, train_losses, val_losses, train_mAPs, val_mAPs = train(classifier, num_epochs, train_loader, val_loader, criterion, optimizer, test_frequency)\n","\n","  torch.save(classifier.state_dict(), './classifier_adding8.pth')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Starting epoch number 1\n","Loss for Training on Epoch 1 is 0.05006292834877968\n","last one: My_classes[i]: two cars, y_true[:, i]:max:1.0, min:0.0\n","-------  Class: 0                AP:   0.9814  -------\n","-------  Class: 1                AP:   0.9805  -------\n","-------  Class: 2                AP:   0.9622  -------\n","-------  Class: 3                AP:   0.9672  -------\n","-------  Class: 4                AP:   0.9869  -------\n","-------  Class: 5                AP:   0.9139  -------\n","-------  Class: 6                AP:   0.9913  -------\n","-------  Class: 7                AP:   0.9500  -------\n","-------  Class: 8                AP:   0.9409  -------\n","-------  Class: 9                AP:   0.9987  -------\n","-------  Class: 10               AP:   0.9998  -------\n","-------  Class: 11               AP:   0.9927  -------\n","-------  Class: 12               AP:   1.0000  -------\n","-------  Class: 13               AP:   0.9979  -------\n","-------  Class: 14               AP:   0.9963  -------\n","-------  Class: 15               AP:   0.9999  -------\n","-------  Class: 16               AP:   0.9976  -------\n","-------  Class: 17               AP:   0.9987  -------\n","-------  Class: 18               AP:   0.9841  -------\n","-------  Class: 19               AP:   0.8142  -------\n","-------  Class: 20               AP:   0.9258  -------\n","-------  Class: 21               AP:   0.8770  -------\n","-------  Class: 22               AP:   0.9999  -------\n","-------  Class: 23               AP:   0.9569  -------\n","-------  Class: 24               AP:   0.9009  -------\n","-------  Class: 25               AP:   0.9944  -------\n","-------  Class: 26               AP:   0.9925  -------\n","-------  Class: 27               AP:   0.9808  -------\n","-------  Class: 28               AP:   0.9088  -------\n","-------  Class: 29               AP:   0.9640  -------\n","-------  Class: 30               AP:   0.9587  -------\n","-------  Class: 31               AP:   0.9941  -------\n","-------  Class: 32               AP:   0.9494  -------\n","-------  Class: 33               AP:   0.9965  -------\n","-------  Class: 34               AP:   0.9953  -------\n","-------  Class: 35               AP:   0.9961  -------\n","-------  Class: 36               AP:   0.9488  -------\n","-------  Class: 37               AP:   0.9679  -------\n","-------  Class: 38               AP:   0.9981  -------\n","-------  Class: 39               AP:   0.9970  -------\n","-------  Class: 40               AP:   0.9621  -------\n","-------  Class: 41               AP:   0.9234  -------\n","-------  Class: 42               AP:   0.9727  -------\n","-------  Class: red              AP:   1.0000  -------\n","-------  Class: blue             AP:   1.0000  -------\n","-------  Class: black            AP:   1.0000  -------\n","-------  Class: circle           AP:   0.9999  -------\n","-------  Class: triangle         AP:   1.0000  -------\n","-------  Class: blk cross line     AP:   0.9984  -------\n","-------  Class: number 8         AP:   0.9296  -------\n","-------  Class: number 2         AP:   0.9187  -------\n","-------  Class: number 1         AP:   0.9928  -------\n","-------  Class: number 0         AP:   1.0000  -------\n","-------  Class: car and truck     AP:   0.9998  -------\n","last one: My_classes[i]: two cars, y_true[:, i]:max:1.0, min:0.0\n","-------  Class: two cars         AP:   0.9935  -------\n","mAP: 0.9718\n","Avg loss: 0.012671044387388974\n","Evaluating classifier\n","Mean Precision Score for Testing on Epoch 1 is 0.9717844219968023\n","Starting epoch number 2\n","Loss for Training on Epoch 2 is 0.009600406512618065\n","last one: My_classes[i]: two cars, y_true[:, i]:max:1.0, min:0.0\n","-------  Class: 0                AP:   0.9901  -------\n","-------  Class: 1                AP:   0.9975  -------\n","-------  Class: 2                AP:   0.9930  -------\n","-------  Class: 3                AP:   0.9839  -------\n","-------  Class: 4                AP:   0.9979  -------\n","-------  Class: 5                AP:   0.9798  -------\n","-------  Class: 6                AP:   0.9984  -------\n","-------  Class: 7                AP:   0.9924  -------\n","-------  Class: 8                AP:   0.9760  -------\n","-------  Class: 9                AP:   0.9986  -------\n","-------  Class: 10               AP:   0.9999  -------\n","-------  Class: 11               AP:   0.9968  -------\n","-------  Class: 12               AP:   1.0000  -------\n","-------  Class: 13               AP:   0.9998  -------\n","-------  Class: 14               AP:   0.9959  -------\n","-------  Class: 15               AP:   0.9999  -------\n","-------  Class: 16               AP:   1.0000  -------\n","-------  Class: 17               AP:   0.9995  -------\n","-------  Class: 18               AP:   0.9971  -------\n","-------  Class: 19               AP:   0.8805  -------\n","-------  Class: 20               AP:   0.9996  -------\n","-------  Class: 21               AP:   0.9798  -------\n","-------  Class: 22               AP:   1.0000  -------\n","-------  Class: 23               AP:   0.9879  -------\n","-------  Class: 24               AP:   0.9881  -------\n","-------  Class: 25               AP:   0.9969  -------\n","-------  Class: 26               AP:   0.9995  -------\n","-------  Class: 27               AP:   1.0000  -------\n","-------  Class: 28               AP:   0.9830  -------\n","-------  Class: 29               AP:   0.9996  -------\n","-------  Class: 30               AP:   0.9784  -------\n","-------  Class: 31               AP:   0.9983  -------\n","-------  Class: 32               AP:   0.9995  -------\n","-------  Class: 33               AP:   0.9992  -------\n","-------  Class: 34               AP:   1.0000  -------\n","-------  Class: 35               AP:   0.9998  -------\n","-------  Class: 36               AP:   0.9949  -------\n","-------  Class: 37               AP:   0.9967  -------\n","-------  Class: 38               AP:   0.9993  -------\n","-------  Class: 39               AP:   1.0000  -------\n","-------  Class: 40               AP:   0.9813  -------\n","-------  Class: 41               AP:   0.9947  -------\n","-------  Class: 42               AP:   0.9964  -------\n","-------  Class: red              AP:   1.0000  -------\n","-------  Class: blue             AP:   1.0000  -------\n","-------  Class: black            AP:   1.0000  -------\n","-------  Class: circle           AP:   0.9999  -------\n","-------  Class: triangle         AP:   1.0000  -------\n","-------  Class: blk cross line     AP:   0.9991  -------\n","-------  Class: number 8         AP:   0.9833  -------\n","-------  Class: number 2         AP:   0.9819  -------\n","-------  Class: number 1         AP:   0.9955  -------\n","-------  Class: number 0         AP:   0.9999  -------\n","-------  Class: car and truck     AP:   0.9999  -------\n","last one: My_classes[i]: two cars, y_true[:, i]:max:1.0, min:0.0\n","-------  Class: two cars         AP:   0.9980  -------\n","mAP: 0.9929\n","Avg loss: 0.005812664375179852\n","Evaluating classifier\n","Mean Precision Score for Testing on Epoch 2 is 0.9928581787657536\n","Starting epoch number 3\n","Loss for Training on Epoch 3 is 0.004523028619587421\n","last one: My_classes[i]: two cars, y_true[:, i]:max:1.0, min:0.0\n","-------  Class: 0                AP:   0.9985  -------\n","-------  Class: 1                AP:   0.9981  -------\n","-------  Class: 2                AP:   0.9982  -------\n","-------  Class: 3                AP:   0.9924  -------\n","-------  Class: 4                AP:   0.9999  -------\n","-------  Class: 5                AP:   0.9957  -------\n","-------  Class: 6                AP:   0.9993  -------\n","-------  Class: 7                AP:   0.9991  -------\n","-------  Class: 8                AP:   0.9936  -------\n","-------  Class: 9                AP:   1.0000  -------\n","-------  Class: 10               AP:   1.0000  -------\n","-------  Class: 11               AP:   0.9998  -------\n","-------  Class: 12               AP:   1.0000  -------\n","-------  Class: 13               AP:   1.0000  -------\n","-------  Class: 14               AP:   0.9991  -------\n","-------  Class: 15               AP:   1.0000  -------\n","-------  Class: 16               AP:   1.0000  -------\n","-------  Class: 17               AP:   0.9993  -------\n","-------  Class: 18               AP:   0.9994  -------\n","-------  Class: 19               AP:   0.9742  -------\n","-------  Class: 20               AP:   0.9984  -------\n","-------  Class: 21               AP:   0.9998  -------\n","-------  Class: 22               AP:   1.0000  -------\n","-------  Class: 23               AP:   0.9949  -------\n","-------  Class: 24               AP:   0.9943  -------\n","-------  Class: 25               AP:   0.9996  -------\n","-------  Class: 26               AP:   0.9999  -------\n","-------  Class: 27               AP:   1.0000  -------\n","-------  Class: 28               AP:   0.9978  -------\n","-------  Class: 29               AP:   1.0000  -------\n","-------  Class: 30               AP:   0.9918  -------\n","-------  Class: 31               AP:   0.9998  -------\n","-------  Class: 32               AP:   0.9990  -------\n","-------  Class: 33               AP:   1.0000  -------\n","-------  Class: 34               AP:   1.0000  -------\n","-------  Class: 35               AP:   1.0000  -------\n","-------  Class: 36               AP:   1.0000  -------\n","-------  Class: 37               AP:   1.0000  -------\n","-------  Class: 38               AP:   1.0000  -------\n","-------  Class: 39               AP:   1.0000  -------\n","-------  Class: 40               AP:   0.9998  -------\n","-------  Class: 41               AP:   1.0000  -------\n","-------  Class: 42               AP:   1.0000  -------\n","-------  Class: red              AP:   1.0000  -------\n","-------  Class: blue             AP:   1.0000  -------\n","-------  Class: black            AP:   1.0000  -------\n","-------  Class: circle           AP:   1.0000  -------\n","-------  Class: triangle         AP:   1.0000  -------\n","-------  Class: blk cross line     AP:   1.0000  -------\n","-------  Class: number 8         AP:   0.9963  -------\n","-------  Class: number 2         AP:   0.9947  -------\n","-------  Class: number 1         AP:   0.9986  -------\n","-------  Class: number 0         AP:   1.0000  -------\n","-------  Class: car and truck     AP:   1.0000  -------\n","last one: My_classes[i]: two cars, y_true[:, i]:max:1.0, min:0.0\n","-------  Class: two cars         AP:   0.9999  -------\n","mAP: 0.9984\n","Avg loss: 0.0024734530087026424\n","Evaluating classifier\n","Mean Precision Score for Testing on Epoch 3 is 0.9983840810818183\n","Starting epoch number 4\n","Loss for Training on Epoch 4 is 0.0028304567094892263\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SjgDcuP8iyu_","executionInfo":{"status":"aborted","timestamp":1605755017880,"user_tz":480,"elapsed":133613,"user":{"displayName":"Mohammad Karimi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhscZnXMfUg_B5TiqiYQWTpwdoSQgf3KMBVqAvcdx0=s64","userId":"12774174295451066351"}}},"source":["if 1:\n","  plot_losses(train_losses, val_losses, test_frequency, num_epochs)\n","  plot_mAP(train_mAPs, val_mAPs, test_frequency, num_epochs)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"m7ctwMnR2spr","executionInfo":{"status":"aborted","timestamp":1605755017881,"user_tz":480,"elapsed":133608,"user":{"displayName":"Mohammad Karimi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhscZnXMfUg_B5TiqiYQWTpwdoSQgf3KMBVqAvcdx0=s64","userId":"12774174295451066351"}}},"source":["if 1:\n","  mAP_test, test_loss, test_aps = test_classifier(test_loader, classifier, criterion)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vA_mSgusr-Vt"},"source":["# Saving variables\n","This section I will save the variables in my session so I can process them later. I use Pickle to write and read."]},{"cell_type":"code","metadata":{"id":"h79wQA2ZsnbW","executionInfo":{"status":"aborted","timestamp":1605755017882,"user_tz":480,"elapsed":133602,"user":{"displayName":"Mohammad Karimi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhscZnXMfUg_B5TiqiYQWTpwdoSQgf3KMBVqAvcdx0=s64","userId":"12774174295451066351"}}},"source":["# file = open(\"./results.pkl\",'rb')\n","# mAP_test, test_loss, test_aps, classifier = pickle.load(file)\n","# file.close()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cDBAh6tcv8nx"},"source":["Save variables using pickle"]},{"cell_type":"code","metadata":{"id":"eG7_QRCkDxdr","executionInfo":{"status":"aborted","timestamp":1605755017882,"user_tz":480,"elapsed":133596,"user":{"displayName":"Mohammad Karimi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhscZnXMfUg_B5TiqiYQWTpwdoSQgf3KMBVqAvcdx0=s64","userId":"12774174295451066351"}}},"source":["f = open(result_path + \"./MY_results_adding8.pkl\",\"wb\")\n","pickle.dump([train_losses, val_losses, train_mAPs, val_mAPs, classifier, test_frequency, num_epochs], f)\n","f.close()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fKP7EfGUvsPU"},"source":["read from pickle file"]},{"cell_type":"code","metadata":{"id":"tkP5nx1xk3xM","executionInfo":{"status":"aborted","timestamp":1605755017883,"user_tz":480,"elapsed":133590,"user":{"displayName":"Mohammad Karimi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhscZnXMfUg_B5TiqiYQWTpwdoSQgf3KMBVqAvcdx0=s64","userId":"12774174295451066351"}}},"source":[" \n","# file = open(\"./results.pkl\", 'rb')\n","# train_losses, val_losses, train_mAPs, val_mAPs, classifier, test_frequency, num_epochs = pickle.load(file)\n","# file.close()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7f6_RlU3ht6a"},"source":["# Analysis of the results\n"]},{"cell_type":"markdown","metadata":{"id":"4i3ag3efst05"},"source":["## Regenerating the results\n","Lets re-generate the results for train\\val\\test datasets"]},{"cell_type":"code","metadata":{"id":"tUorzviBDNPh","executionInfo":{"status":"aborted","timestamp":1605755017884,"user_tz":480,"elapsed":133584,"user":{"displayName":"Mohammad Karimi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhscZnXMfUg_B5TiqiYQWTpwdoSQgf3KMBVqAvcdx0=s64","userId":"12774174295451066351"}}},"source":["def classifier_output(test_loader, classifier):\n","    classifier.eval()\n","    with torch.no_grad():\n","        y_true = np.zeros((0,num_classes))\n","        y_score = np.zeros((0,num_classes))\n","        for i, (images, labels, _) in enumerate(test_loader):\n","            images, labels = images.to(device), labels.to(device)\n","            logits = classifier(images)\n","            y_true = np.concatenate((y_true, labels.cpu().numpy()), axis=0)\n","            y_score = np.concatenate((y_score, logits.cpu().numpy()), axis=0)\n","    return y_score, y_true"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SfcSpEeqljpS","executionInfo":{"status":"aborted","timestamp":1605755017886,"user_tz":480,"elapsed":133580,"user":{"displayName":"Mohammad Karimi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhscZnXMfUg_B5TiqiYQWTpwdoSQgf3KMBVqAvcdx0=s64","userId":"12774174295451066351"}}},"source":["# mAP_train, train_loss, train_aps = test_classifier(train_loader, classifier, criterion)\n","\n","# mAP_val, val_loss, val_aps = test_classifier(val_loader, classifier, criterion)\n","\n","# mAP_test, test_loss, test_aps = test_classifier(test_loader, classifier, criterion)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jFiovDTErEPD","executionInfo":{"status":"aborted","timestamp":1605755017887,"user_tz":480,"elapsed":133571,"user":{"displayName":"Mohammad Karimi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhscZnXMfUg_B5TiqiYQWTpwdoSQgf3KMBVqAvcdx0=s64","userId":"12774174295451066351"}}},"source":["train_output, train_target = classifier_output(train_loader, classifier)\n","val_output, val_target = classifier_output(val_loader, classifier)\n","test_output, test_target = classifier_output(test_loader, classifier)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tfIKF2nbj6G7","executionInfo":{"status":"aborted","timestamp":1605755017887,"user_tz":480,"elapsed":133563,"user":{"displayName":"Mohammad Karimi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhscZnXMfUg_B5TiqiYQWTpwdoSQgf3KMBVqAvcdx0=s64","userId":"12774174295451066351"}}},"source":["f = open(result_path + \"./first_resp_adding8.pkl\",\"wb\")\n","pickle.dump([train_output, train_target, val_output, val_target, test_output, test_target], f)\n","f.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZvQ7421nkIwQ","executionInfo":{"status":"aborted","timestamp":1605755017888,"user_tz":480,"elapsed":133556,"user":{"displayName":"Mohammad Karimi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhscZnXMfUg_B5TiqiYQWTpwdoSQgf3KMBVqAvcdx0=s64","userId":"12774174295451066351"}}},"source":["# file = open(\"./first_resp.pkl\", 'rb')\n","# train_output, train_target, val_output, val_target, test_output, test_target = pickle.load(file)\n","# file.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1ScKkEPniyvE","executionInfo":{"status":"aborted","timestamp":1605755017888,"user_tz":480,"elapsed":133548,"user":{"displayName":"Mohammad Karimi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhscZnXMfUg_B5TiqiYQWTpwdoSQgf3KMBVqAvcdx0=s64","userId":"12774174295451066351"}}},"source":["# torch.save(classifier.state_dict(), './voc_my_best_classifier.pth')\n","# output_submission_csv('my_solution.csv', test_aps)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gLMbfHtaIeHN","executionInfo":{"status":"aborted","timestamp":1605755017889,"user_tz":480,"elapsed":133539,"user":{"displayName":"Mohammad Karimi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhscZnXMfUg_B5TiqiYQWTpwdoSQgf3KMBVqAvcdx0=s64","userId":"12774174295451066351"}}},"source":["M = 702\n","print(train_output[M])\n","# print(train_logits[M])\n","\n","print(\"==========\")\n","print(train_target[M])\n","print(\"=======\")\n","for i,target in enumerate(train_target[M]):\n","  if target>0:\n","    print(i)\n","    print(train_output[M][i])\n","    # print(train_logits[M][i])\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cJJcYAGEjLP_","executionInfo":{"status":"aborted","timestamp":1605755017889,"user_tz":480,"elapsed":133531,"user":{"displayName":"Mohammad Karimi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhscZnXMfUg_B5TiqiYQWTpwdoSQgf3KMBVqAvcdx0=s64","userId":"12774174295451066351"}}},"source":["y_resp = np.zeros(train_output[1].shape)\n","y_resp[train_output[1]>0]=1\n","y_resp\n","print(y_resp)\n","print(train_target[1])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"v6uPwElYiVEZ","executionInfo":{"status":"aborted","timestamp":1605755017890,"user_tz":480,"elapsed":133524,"user":{"displayName":"Mohammad Karimi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhscZnXMfUg_B5TiqiYQWTpwdoSQgf3KMBVqAvcdx0=s64","userId":"12774174295451066351"}}},"source":["for i,target in enumerate(train_target):\n","  y_resp = np.zeros(train_output[i].shape)\n","  y_resp[train_output[i]>0]=1\n","  if target[:43]!=y_resp[:43]:\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"q95nRUg54hAs"},"source":["# Creating the second classifier\n","Here we create the second classifier to get the result from the first classifier with extended output and estimate 43 class of traffic signs.\n"]},{"cell_type":"markdown","metadata":{"id":"DMr1FSTL2HHQ"},"source":["defining the parameters:"]},{"cell_type":"code","metadata":{"id":"8H2VRtK_2GVS","executionInfo":{"status":"aborted","timestamp":1605755017890,"user_tz":480,"elapsed":133516,"user":{"displayName":"Mohammad Karimi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhscZnXMfUg_B5TiqiYQWTpwdoSQgf3KMBVqAvcdx0=s64","userId":"12774174295451066351"}}},"source":["GTSRB_num_classes = 43\n","extInp_num_classes = num_classes"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zub0vz--1VIz"},"source":["defining a class to get the output of the first classifire. then we will give the output to the next_classifier"]},{"cell_type":"code","metadata":{"id":"HAb-71Vw086Q","executionInfo":{"status":"aborted","timestamp":1605755017891,"user_tz":480,"elapsed":133506,"user":{"displayName":"Mohammad Karimi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhscZnXMfUg_B5TiqiYQWTpwdoSQgf3KMBVqAvcdx0=s64","userId":"12774174295451066351"}}},"source":["def next_train(classifier, num_epochs, train_loader, val_loader, criterion, optimizer, test_frequency=5):\n","    train_losses = []\n","    train_mAPs = []\n","    val_losses = []\n","    val_mAPs = []\n","    decayRate = 0.96\n","    \n","\n","    for epoch in range(1,num_epochs+1):\n","        print(\"Starting epoch number \" + str(epoch))\n","        train_loss = next_train_classifier(train_loader, classifier, criterion, optimizer)\n","        train_losses.append(train_loss)\n","        #lr_scheduler.step()\n","        #print('learning rate :', get_lr(lr_scheduler.optimizer))\n","\n","        print(\"Loss for Training on Epoch \" +str(epoch) + \" is \"+ str(train_loss))\n","        if(epoch%test_frequency==0 or epoch==1):\n","            mAP_train, _, _ = next_test_classifier(train_loader, classifier, criterion, False, False)\n","            train_mAPs.append(mAP_train)\n","            mAP_val, val_loss, _ = next_test_classifier(val_loader, classifier, criterion)\n","            print('Evaluating classifier')\n","            print(\"Mean Precision Score for Testing on Epoch \" +str(epoch) + \" is \"+ str(mAP_val))\n","            val_losses.append(val_loss)\n","            val_mAPs.append(mAP_val)\n","    \n","    return classifier, train_losses, val_losses, train_mAPs, val_mAPs\n","\n","def next_train_classifier(train_loader, classifier, criterion, optimizer):\n","    classifier.train()\n","    loss_ = 0.0\n","    losses = []\n","    for i, (input, labels) in enumerate(train_loader):\n","        input, labels = input.to(device), labels.to(device)\n","        optimizer.zero_grad()\n","        logits = classifier(input)\n","        loss = criterion(logits, labels)\n","        loss.backward()\n","        optimizer.step()\n","        losses.append(loss)\n","    return torch.stack(losses).mean().item()\n","\n","\n","def next_test_classifier(test_loader, classifier, criterion, print_ind_classes=True, print_total=True):\n","    classifier.eval()\n","    losses = []\n","    with torch.no_grad():\n","        y_true = np.zeros((0,GTSRB_num_classes))\n","        y_score = np.zeros((0,GTSRB_num_classes))\n","        for i, (input, labels) in enumerate(test_loader):\n","            input, labels = input.to(device), labels.to(device)\n","            logits = classifier(input)\n","            y_true = np.concatenate((y_true, labels.cpu().numpy()), axis=0)\n","            y_score = np.concatenate((y_score, logits.cpu().numpy()), axis=0)\n","            loss = criterion(logits, labels)\n","            losses.append(loss.item())\n","        aps = []\n","        # ignore first class which is background\n","        for i in range(0, y_true.shape[1]):\n","            ap = average_precision_score(y_true[:, i], y_score[:, i])\n","            if print_ind_classes:\n","                print('-------  Class: {:<12}     AP: {:>8.4f}  -------'.format(My_classes[i], ap))\n","            aps.append(ap)\n","        \n","        mAP = np.mean(aps)\n","        test_loss = np.mean(losses)\n","        if print_total:\n","            print('mAP: {0:.4f}'.format(mAP))\n","            print('Avg loss: {}'.format(test_loss))\n","        \n","    return mAP, test_loss, aps\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JzOu5cNw4gp7","executionInfo":{"status":"aborted","timestamp":1605755017891,"user_tz":480,"elapsed":133492,"user":{"displayName":"Mohammad Karimi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhscZnXMfUg_B5TiqiYQWTpwdoSQgf3KMBVqAvcdx0=s64","userId":"12774174295451066351"}}},"source":["GTSRB_num_classes = 43\n","extInp_num_classes = num_classes\n","import torch.nn.functional as F\n","\n","\n","class next_classifier(nn.Module):\n","    def __init__(self):\n","        #super() allows you to build classes that easily extend the functionality of previously built classes without implementing their functionality again.\n","        super(next_classifier, self).__init__()\n","        self.fc1 = nn.Linear(in_features=extInp_num_classes, out_features=500, bias=True)\n","        self.fc2 = nn.Linear(in_features=500, out_features=500, bias=True)\n","        self.fc3 = nn.Linear(in_features=500, out_features=GTSRB_num_classes, bias=True)\n","        self.drop = nn.Dropout(p=0.2, inplace=False)\n","\n","    def forward(self, x):\n","        x = F.relu(self.fc1(x))\n","        x = self.drop(x)\n","        x = F.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8Diah73_d0a1","executionInfo":{"status":"aborted","timestamp":1605755017892,"user_tz":480,"elapsed":133477,"user":{"displayName":"Mohammad Karimi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhscZnXMfUg_B5TiqiYQWTpwdoSQgf3KMBVqAvcdx0=s64","userId":"12774174295451066351"}}},"source":["import sys\n","import os, numpy as np\n","import torch\n","import torch.utils.data as data\n","\n","class NextDataset(data.Dataset):\n","    def __init__(self, input, labels):\n","        self.input = np.array(input).astype(np.float32)\n","        self.labels = np.array(labels).astype(np.float32)\n","        # self.num_trafficsigns = 43\n","\n","    def __getitem__(self, index):\n","        x = self.input[index]\n","        y = self.labels[index]\n","        return x, y\n","\n","    def __len__(self):\n","        return len(self.labels)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ICpt2kcyCRDn","executionInfo":{"status":"aborted","timestamp":1605755017892,"user_tz":480,"elapsed":133459,"user":{"displayName":"Mohammad Karimi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhscZnXMfUg_B5TiqiYQWTpwdoSQgf3KMBVqAvcdx0=s64","userId":"12774174295451066351"}}},"source":["next_classifier = next_classifier().to(device)\n","optimizer = torch.optim.SGD(next_classifier.parameters(), lr=0.05, momentum=0.9)\n","criterion = nn.MultiLabelSoftMarginLoss()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MVPfzwbMARDZ"},"source":["Normalize the data here:\n"]},{"cell_type":"code","metadata":{"id":"VkmX4WE6AT3J","executionInfo":{"status":"aborted","timestamp":1605755017892,"user_tz":480,"elapsed":133436,"user":{"displayName":"Mohammad Karimi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhscZnXMfUg_B5TiqiYQWTpwdoSQgf3KMBVqAvcdx0=s64","userId":"12774174295451066351"}}},"source":["train_output_n = train_output/100\n","val_output_n = val_output/100\n","test_output_n = test_output/100"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LeDehAr8eEz8","executionInfo":{"status":"aborted","timestamp":1605755017893,"user_tz":480,"elapsed":133424,"user":{"displayName":"Mohammad Karimi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhscZnXMfUg_B5TiqiYQWTpwdoSQgf3KMBVqAvcdx0=s64","userId":"12774174295451066351"}}},"source":["ds_next_train = NextDataset(np.array(train_output_n).astype(np.float32), np.array(train_target[:,:43]).astype(np.float32))\n","ds_next_val = NextDataset(np.array(val_output_n).astype(np.float32), np.array(val_target[:,:43]).astype(np.float32))\n","ds_next_test = NextDataset(np.array(test_output_n).astype(np.float32), np.array(test_target[:,:43]).astype(np.float32))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3B3XExRjWNHY","executionInfo":{"status":"aborted","timestamp":1605755017893,"user_tz":480,"elapsed":133416,"user":{"displayName":"Mohammad Karimi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhscZnXMfUg_B5TiqiYQWTpwdoSQgf3KMBVqAvcdx0=s64","userId":"12774174295451066351"}}},"source":["\n","\n","num_epochs = 5\n","test_frequency = 5\n","batch_size = 64\n","\n","next_train_loader = torch.utils.data.DataLoader(dataset=ds_next_train,\n","                                               batch_size=batch_size, \n","                                               shuffle=False,\n","                                               num_workers=1)\n","\n","next_val_loader = torch.utils.data.DataLoader(dataset=ds_next_val,\n","                                               batch_size=batch_size, \n","                                               shuffle=False,\n","                                               num_workers=1)\n","\n","next_test_loader = torch.utils.data.DataLoader(dataset=ds_next_test,\n","                                               batch_size=batch_size, \n","                                               shuffle=False,\n","                                               num_workers=1)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oOxL1YLHLQ5z","executionInfo":{"status":"aborted","timestamp":1605755017894,"user_tz":480,"elapsed":133409,"user":{"displayName":"Mohammad Karimi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhscZnXMfUg_B5TiqiYQWTpwdoSQgf3KMBVqAvcdx0=s64","userId":"12774174295451066351"}}},"source":["next_classifier, train_losses_1, val_losses_1, train_mAPs_1, val_mAPs_1 = next_train(next_classifier, num_epochs, next_train_loader, next_val_loader, criterion, optimizer, test_frequency)\n","\n","torch.save(classifier.state_dict(), './classifier2.pth')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UA2Xjk2Adys0","executionInfo":{"status":"aborted","timestamp":1605755017894,"user_tz":480,"elapsed":133402,"user":{"displayName":"Mohammad Karimi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhscZnXMfUg_B5TiqiYQWTpwdoSQgf3KMBVqAvcdx0=s64","userId":"12774174295451066351"}}},"source":["next_mAP_test, next_test_loss, next_test_aps = next_test_classifier(next_test_loader, next_classifier, criterion)"],"execution_count":null,"outputs":[]}]}